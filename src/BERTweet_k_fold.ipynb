{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTweet_k-fold.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ksNIfV1hIB0N",
        "QLJ9Wss9S2uL",
        "kha-zT_yTBNg",
        "k-kQ0VDXrsP-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ef42ebe5bcb4df4ba5fce19f4895c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bdd86a3bf5a9443aac6aa523614d4d78",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1fb21c0bf654433f9c4aad6f0f3b895e",
              "IPY_MODEL_7453b298b4e84e4db6187cadd0eaf3cc",
              "IPY_MODEL_d0768fe3cee844a697fbe81e4a341d58"
            ]
          }
        },
        "bdd86a3bf5a9443aac6aa523614d4d78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fb21c0bf654433f9c4aad6f0f3b895e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f0015f92be5460eae1eaa47423eb256",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a21b7ae4b87d4702aecc1e764a484b67"
          }
        },
        "7453b298b4e84e4db6187cadd0eaf3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10ba2cd4be214565bc21a34fdb42fb99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 558,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 558,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd938cc7f068457aa6d8e85e4485e6aa"
          }
        },
        "d0768fe3cee844a697fbe81e4a341d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_30fdd561dec54e24a4b702f1bf289503",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 558/558 [00:00&lt;00:00, 12.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0095e31705634e0b9177b528e0f7ac9b"
          }
        },
        "6f0015f92be5460eae1eaa47423eb256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a21b7ae4b87d4702aecc1e764a484b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10ba2cd4be214565bc21a34fdb42fb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd938cc7f068457aa6d8e85e4485e6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30fdd561dec54e24a4b702f1bf289503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0095e31705634e0b9177b528e0f7ac9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b7582c20807495899d8444da4067bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_439d5af5f2464dd1b5003ad8c7b1ae08",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_620a687f63b54ffd827c51504a30fd98",
              "IPY_MODEL_e015fd0e7be14a3a8267d81d66da2bab",
              "IPY_MODEL_8f1abd2eb1644c6d9e9e2bb7b4fd55da"
            ]
          }
        },
        "439d5af5f2464dd1b5003ad8c7b1ae08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "620a687f63b54ffd827c51504a30fd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a72d83d634648378a78bc051ecae347",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6318d24ca937408083a42c08c449e7fe"
          }
        },
        "e015fd0e7be14a3a8267d81d66da2bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c678eba20e64f9bb7657305d7a827e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 843438,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 843438,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8984fb78ce4489a85a5bfc42d423bce"
          }
        },
        "8f1abd2eb1644c6d9e9e2bb7b4fd55da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e4009928a234207b9b33f25e83554dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 843k/843k [00:00&lt;00:00, 2.05MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f9196d17e1d409bada4e2e1167c8465"
          }
        },
        "8a72d83d634648378a78bc051ecae347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6318d24ca937408083a42c08c449e7fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c678eba20e64f9bb7657305d7a827e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8984fb78ce4489a85a5bfc42d423bce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e4009928a234207b9b33f25e83554dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f9196d17e1d409bada4e2e1167c8465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "214a871acd974d45856b981348fd3be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a97bb1786b894d5da29ef357ae01cfeb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4538aecb8d6f47b08324efe23b5f0f49",
              "IPY_MODEL_b4f64b6a5c01417fb0e2b3e09977ee59",
              "IPY_MODEL_51326b99388a4e51a648e1e408d28ce0"
            ]
          }
        },
        "a97bb1786b894d5da29ef357ae01cfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4538aecb8d6f47b08324efe23b5f0f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0554f7bf23ed44e6893f04eadd861fd3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c07c1a59d89422085e0772982c0af85"
          }
        },
        "b4f64b6a5c01417fb0e2b3e09977ee59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa826b14b2494a278a93742b07c84752",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1078931,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1078931,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e5e506c2c3f4d438a47e95c08014338"
          }
        },
        "51326b99388a4e51a648e1e408d28ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_210e8dc5846f49b78df533de9a60b389",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.08M/1.08M [00:00&lt;00:00, 3.24MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e78d068de1e34f35bd5deb71d42e079b"
          }
        },
        "0554f7bf23ed44e6893f04eadd861fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c07c1a59d89422085e0772982c0af85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa826b14b2494a278a93742b07c84752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e5e506c2c3f4d438a47e95c08014338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "210e8dc5846f49b78df533de9a60b389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e78d068de1e34f35bd5deb71d42e079b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60f6110e0b4949c4910099a6c045762b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3819806d9b7f48b6a3ba9a2dc884faad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec376cbe84c941e3aa00212abd5f88f1",
              "IPY_MODEL_16aa11fd18424033ac3a45e759da6cdc",
              "IPY_MODEL_1c43c7b0d42749829cc2d6f3138e7b71"
            ]
          }
        },
        "3819806d9b7f48b6a3ba9a2dc884faad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec376cbe84c941e3aa00212abd5f88f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21f31a2f19f74622aa51d30f701db03f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b1882c24a144d3d8b73662e3339094e"
          }
        },
        "16aa11fd18424033ac3a45e759da6cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9078f1a2ace3448fb2fc55d4ea63196e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 542529064,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 542529064,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1757e054198e40a0bd457032e3ca427a"
          }
        },
        "1c43c7b0d42749829cc2d6f3138e7b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ecd85f800fa49f89a390ae5c588306f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 543M/543M [00:11&lt;00:00, 48.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73da7276eb484ae3b0aa88244c865f36"
          }
        },
        "21f31a2f19f74622aa51d30f701db03f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b1882c24a144d3d8b73662e3339094e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9078f1a2ace3448fb2fc55d4ea63196e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1757e054198e40a0bd457032e3ca427a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ecd85f800fa49f89a390ae5c588306f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73da7276eb484ae3b0aa88244c865f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ixomaxip/nasoc/blob/master/src/BERTweet_k_fold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8SipYd8wXSs",
        "outputId": "a2da2981-f88f-4a30-bd09-0b56f8aa85ba"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 11 01:54:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    26W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ToLnryTqUg-"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install nltk emoji\n",
        "!pip install tweet-preprocessor\n",
        "\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "\n",
        "!wget https://hasocfire.github.io/hasoc/2021/files/en_Hasoc2021_train.zip\n",
        "!unzip -P hasoc2021_en en_Hasoc2021_train.zip\n",
        "!ls\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVRtn1TZSxGK",
        "outputId": "da81a2a4-cc4b-41a5-d2c6-9181940fa7b3"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARQ02wGdHGXR"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# !rm -rf /root/.ssh\n",
        "# !mkdir /root/.ssh\n",
        "# # !tar -xvzf ssh.tar.gz -C /root/.ssh && rm -rf ssh.tar.gz && chmod 700 /root/.ssh\n",
        "# !tar -xvzf ssh.tar.gz -C /root/.ssh && rm -rf ssh.tar.gz\n",
        "# !ssh-keyscan -t rsa github.com >> /root/.ssh/known_hosts\n",
        "\n",
        "# !git config --global user.email 'ixomaxip@gmail.com'\n",
        "# !git config --global user.user 'ixomaxip'\n",
        "# !ssh -T git@github.com\n",
        "\n",
        "# !git clone git@github.com:ixomaxip/nasoc.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJEJm7ejkEJ9"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksNIfV1hIB0N"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YesKuvGvmyMD",
        "outputId": "80ba54cd-274a-476c-a35f-2705dddf0785"
      },
      "source": [
        "FULL_PATH = '/content/nasoc/data/en_Hasoc2021_train.csv'\n",
        "TRAIN_PATH = '/content/nasoc/data/train.csv'\n",
        "TEST_PATH = '/content/nasoc/data/validate.csv'\n",
        "\n",
        "full_df = pd.read_csv(FULL_PATH)\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "print(f'''shapes:\n",
        "  full: {full_df.shape}\n",
        "  train: {train_df.shape}\n",
        "  test: {test_df.shape}\n",
        "''')\n",
        "print(f'''classes:\n",
        "  task_1: {full_df.task_1.unique()}\n",
        "  task_2: {full_df.task_2.unique()}\n",
        "''')\n",
        "train_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shapes:\n",
            "  full: (3843, 5)\n",
            "  train: (3074, 7)\n",
            "  test: (769, 7)\n",
            "\n",
            "classes:\n",
            "  task_1: ['HOF' 'NOT']\n",
            "  task_2: ['PRFN' 'OFFN' 'NONE' 'HATE']\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', '_id', 'text', 'task_1', 'task_2', 'inputs',\n",
              "       'task_2_cat'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l7wu0rgxMmw"
      },
      "source": [
        "!wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash \n",
        "import nlu\n",
        "# import nlu-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg77sKGMn621",
        "outputId": "7b731670-6f22-4a7d-e16c-dcd2857b52de"
      },
      "source": [
        "def prepare_df(path, task):\n",
        "  df = pd.read_csv(path)\n",
        "  df.rename(columns={f'task_{task}': 'y'}, inplace=True)\n",
        "  df = df[['text', 'y']]\n",
        "  return df\n",
        "\n",
        "train_t1 = prepare_df(TRAIN_PATH, task=1)\n",
        "test_t1 = prepare_df(TEST_PATH, task=1)\n",
        "train_t1.y.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-aed98b7f0b28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_t1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_t1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_t1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prepare_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLNanEMbte5R"
      },
      "source": [
        "trainable_pipe = nlu.load('xx.embed_sentence.labse train.sentiment')\n",
        "trainable_pipe['sentiment_dl'].setMaxEpochs(60)  \n",
        "trainable_pipe['sentiment_dl'].setLr(0.005)\n",
        "fitted_pipe = trainable_pipe.fit(train_t1)\n",
        "preds = fitted_pipe.predict(train_t1, output_level='document')\n",
        "preds.dropna(inplace=True)\n",
        "\n",
        "print(classification_report(preds['y'], preds['trained_sentiment']))\n",
        "MODEL_PATH = './drive/MyDrive/nasoc/task1/sentiment_dl_baseline_trained'\n",
        "fitted_pipe.save(MODEL_PATH)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiqFRBiIKnML",
        "outputId": "e80dbcc9-458d-4084-e81d-994a8b0ff8d3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndut3lMd9cYZ"
      },
      "source": [
        "preds = fitted_pipe.predict(test_t1, output_level='document')\n",
        "preds.dropna(inplace=True)\n",
        "print(classification_report(preds['y'], preds['trained_sentiment']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KCI5YidQ9rG"
      },
      "source": [
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "DEVICE = torch.device('cuda:0')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/LaBSE-en-ru\")\n",
        "# model = AutoModel.from_pretrained(\"cointegrated/LaBSE-en-ru\")\n",
        "# model.eval().to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEr7NwFTi1jz"
      },
      "source": [
        "def text_encoder(texts, model, tokenizer, max_len=128):\n",
        "    encoded_input = tokenizer(texts, padding=True, truncation=True, max_length=max_len, return_tensors='pt').to(device=DEVICE)\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "    embeddings = model_output.pooler_output\n",
        "    embeddings = torch.nn.functional.normalize(embeddings)\n",
        "\n",
        "    return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUEidAqjcCQl"
      },
      "source": [
        "ROOT_DIR = '/content/drive/MyDrive/nasoc/'\n",
        "TRAIN_EMB = os.path.join(ROOT_DIR, 'train_emb.feather')\n",
        "TEST_EMB = os.path.join(ROOT_DIR, 'test_emb.feather')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLJ9Wss9S2uL"
      },
      "source": [
        "## Get labse embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3LOuRRcb2Sn"
      },
      "source": [
        "# train_df['labse_emb'] = train_df.apply(lambda row: text_encoder(row['text'], model, tokenizer, 64)[0].detach().cpu().numpy(), axis=1)\n",
        "# train_df.to_feather(TRAIN_EMB)\n",
        "\n",
        "# test_df['labse_emb'] = test_df.apply(lambda row: text_encoder(row['text'], model, tokenizer, 64)[0].detach().cpu().numpy(), axis=1)\n",
        "# test_df.to_feather(TEST_EMB)\n",
        "train_df = pd.read_feather(TRAIN_EMB)\n",
        "test_df = pd.read_feather(TEST_EMB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "uegemNBljTBF",
        "outputId": "8595d26e-76a3-43e0-be21-92f85fbc9118"
      },
      "source": [
        "test_df.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task_1</th>\n",
              "      <th>task_2</th>\n",
              "      <th>inputs</th>\n",
              "      <th>task_2_cat</th>\n",
              "      <th>labse_emb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4745</td>\n",
              "      <td>60c5d6bf5659ea5e55def8b8</td>\n",
              "      <td>4lakh cases in a day ðŸ˜” @PMOIndia @drharshva...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.02545384, 0.03337645, 0.020745805, -0.0581...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4795</td>\n",
              "      <td>60c5d6bf5659ea5e55def871</td>\n",
              "      <td>@SiennaSummerEIC @Chantel_Etoile You do unders...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.027386742, -0.0026722655, 0.0048503056, -0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                          labse_emb\n",
              "0        4745  ...  [-0.02545384, 0.03337645, 0.020745805, -0.0581...\n",
              "1        4795  ...  [0.027386742, -0.0026722655, 0.0048503056, -0....\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kha-zT_yTBNg"
      },
      "source": [
        "## XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eEmqAZ5Uj2Y"
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tttg9LqCSxSW",
        "outputId": "4194190e-6c8e-443b-b1db-07e125fa5f46"
      },
      "source": [
        "x_train = np.stack(train_df.labse_emb.to_numpy())\n",
        "y_train = train_df.inputs.values\n",
        "print(x_train.shape)\n",
        "\n",
        "x_test = np.stack(test_df.labse_emb.to_numpy())\n",
        "y_test = test_df.inputs.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3074, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHWl5rlRVv5W",
        "outputId": "04ddc024-d627-491a-b6d8-2bc962c44ab2"
      },
      "source": [
        "bst = xgb.XGBClassifier(\n",
        "    objective='reg:logistic'\n",
        ")\n",
        "\n",
        "bst.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='reg:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gStX7adagUf",
        "outputId": "f861a63d-ca24-46ad-dec4-3dc8b906bfbc"
      },
      "source": [
        "y_pred = bst.predict(x_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84       529\n",
            "           1       0.66      0.47      0.55       240\n",
            "\n",
            "    accuracy                           0.76       769\n",
            "   macro avg       0.73      0.68      0.69       769\n",
            "weighted avg       0.75      0.76      0.75       769\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzoHyRmFiccw",
        "outputId": "54455c02-89db-4905-9f1f-3c059e639a02"
      },
      "source": [
        "row = train_df.iloc[0]\n",
        "text = row.text\n",
        "print(text)\n",
        "emb = text_encoder(row['text'], model, tokenizer, 64)[0].detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@Turbo_Fucker Too bad I'm a dummy not an idiots\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3QnjK3TdjmO"
      },
      "source": [
        "# Custom BERTweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K18B6AOMH599"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "import re\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "#constants and parameters\n",
        "seed = 42\n",
        "\n",
        "path_gdrive_saved = '/content/drive/My Drive/nasoc/bert_tuned.weights'\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "DOWNLOAD_DATASET = False\n",
        "\n",
        "# dataset\n",
        "\n",
        "raw_df = pd.read_csv('en_Hasoc2021_train.csv')\n",
        "\n",
        "raw_df['inputs'] = pd.Categorical(raw_df['task_1'])\n",
        "raw_df['inputs'] = raw_df.inputs.cat.codes\n",
        "\n",
        "raw_df['task_2_cat'] = pd.Categorical(raw_df['task_2'])\n",
        "raw_df['task_2_cat'] = raw_df.task_2_cat.cat.codes\n",
        "\n",
        "train_df, test_df = train_test_split(raw_df, test_size=0.2, random_state=seed)\n",
        "\n",
        "sr_train = train_df.groupby('task_1').count()['text']\n",
        "sr_test  = test_df.groupby('task_1').count()['text']\n",
        "\n",
        "tr_pr = sr_train['NOT']/sr_train['HOF']\n",
        "ts_pr = sr_test['NOT']/sr_test['HOF']\n",
        "\n",
        "#copied from https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)\n",
        "\n",
        "# copied from https://stackoverflow.com/questions/64719706/cleaning-twitter-data-pandas-python\n",
        "def cleaner(tweet):\n",
        "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
        "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
        "    #tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
        "    tweet = \" \".join(tweet.split())\n",
        "    tweet = remove_emojis(tweet)\n",
        "    #tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
        "    #     if w.lower() in words or not w.isalpha())\n",
        "    return tweet\n",
        "\n",
        "\n",
        "train_df, test_df = train_test_split(raw_df, test_size=0.2, random_state=seed)\n",
        "#text = train_df.pop('text')#.map(lambda line: cleaner(line))\n",
        "#label = train_df.pop('inputs')\n",
        "\n",
        "#text_val = test_df.pop('text')#.map(lambda line: cleaner(line))\n",
        "#label_val = test_df.pop('inputs')\n",
        "\n",
        "#train_ds = tf.data.Dataset.from_tensor_slices((text.values, label.values))\n",
        "#val_ds = tf.data.Dataset.from_tensor_slices((text_val.values, label_val.values))\n",
        "\n",
        "#train_ds = train_ds.batch(batch_size=batch_size, drop_remainder=True)\n",
        "#val_ds = val_ds.batch(batch_size=batch_size, drop_remainder=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONcydGgGsaqt"
      },
      "source": [
        "import time, datetime\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F, Linear\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GubgnSZx4jcf"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "0ef42ebe5bcb4df4ba5fce19f4895c59",
            "bdd86a3bf5a9443aac6aa523614d4d78",
            "1fb21c0bf654433f9c4aad6f0f3b895e",
            "7453b298b4e84e4db6187cadd0eaf3cc",
            "d0768fe3cee844a697fbe81e4a341d58",
            "6f0015f92be5460eae1eaa47423eb256",
            "a21b7ae4b87d4702aecc1e764a484b67",
            "10ba2cd4be214565bc21a34fdb42fb99",
            "fd938cc7f068457aa6d8e85e4485e6aa",
            "30fdd561dec54e24a4b702f1bf289503",
            "0095e31705634e0b9177b528e0f7ac9b",
            "3b7582c20807495899d8444da4067bfc",
            "439d5af5f2464dd1b5003ad8c7b1ae08",
            "620a687f63b54ffd827c51504a30fd98",
            "e015fd0e7be14a3a8267d81d66da2bab",
            "8f1abd2eb1644c6d9e9e2bb7b4fd55da",
            "8a72d83d634648378a78bc051ecae347",
            "6318d24ca937408083a42c08c449e7fe",
            "2c678eba20e64f9bb7657305d7a827e0",
            "b8984fb78ce4489a85a5bfc42d423bce",
            "2e4009928a234207b9b33f25e83554dd",
            "8f9196d17e1d409bada4e2e1167c8465",
            "214a871acd974d45856b981348fd3be4",
            "a97bb1786b894d5da29ef357ae01cfeb",
            "4538aecb8d6f47b08324efe23b5f0f49",
            "b4f64b6a5c01417fb0e2b3e09977ee59",
            "51326b99388a4e51a648e1e408d28ce0",
            "0554f7bf23ed44e6893f04eadd861fd3",
            "6c07c1a59d89422085e0772982c0af85",
            "aa826b14b2494a278a93742b07c84752",
            "2e5e506c2c3f4d438a47e95c08014338",
            "210e8dc5846f49b78df533de9a60b389",
            "e78d068de1e34f35bd5deb71d42e079b"
          ]
        },
        "id": "ocg_xpB_hALs",
        "outputId": "ade7e851-1bd7-4d01-e467-b7c63aac59b1"
      },
      "source": [
        "class HasocDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=64, return_tensors='pt')\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "#MODEL_NAME = \"cardiffnlp/twitter-roberta-base-hate\"\n",
        "MODEL_NAME = \"vinai/bertweet-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "train_dataset = HasocDataset(train_df['text'].to_list(), train_df['inputs'].to_list(), tokenizer)\n",
        "test_dataset = HasocDataset(test_df['text'].to_list(), test_df['inputs'].to_list(), tokenizer)\n",
        "\n",
        "raw_dataset = HasocDataset(raw_df['text'].to_list(), train_df['inputs'].to_list(), tokenizer)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = BATCH_SIZE\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            sampler = RandomSampler(test_dataset),\n",
        "            batch_size = BATCH_SIZE\n",
        ")\n",
        "len(train_dataloader)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ef42ebe5bcb4df4ba5fce19f4895c59",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/558 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b7582c20807495899d8444da4067bfc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/843k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "214a871acd974d45856b981348fd3be4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMC2E1uJ4BDQ",
        "outputId": "85861930-9bce-4194-d3a7-82ee71c87763"
      },
      "source": [
        "it = iter(test_dataloader)\n",
        "first = next(it)\n",
        "\n",
        "print(first)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    0,  3919,   221,  ...,     1,     1,     1],\n",
            "        [    0,  5636,   151,  ..., 61558,  6260,     2],\n",
            "        [    0, 18879,    23,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,  3779, 47482,  ...,     1,     1,     1],\n",
            "        [    0,   104,   171,  ...,     1,     1,     1],\n",
            "        [    0,  5238,   450,  ...,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0])}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iNBpJxQGhlc"
      },
      "source": [
        "## Customization class & auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wghRCjFwp5rT"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# DEVICE = torch.device('cpu')\n",
        "\n",
        "# Customization\n",
        "class CustomBERTweet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBERTweet, self).__init__()\n",
        "        self.bertweet = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        #self.cnn = nn.Conv1d(1, 768, 3)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.dense1 = nn.Linear(768, 2)\n",
        "        # self.dense2 = nn.Linear(256, 2)\n",
        "    \n",
        "    def forward(self, feed_dict):\n",
        "\n",
        "        bertweet_output = self.bertweet(**feed_dict)\n",
        "        drop_output = self.dropout(bertweet_output.pooler_output)\n",
        "        linear1_output = self.dense1(drop_output)\n",
        "        # linear2_output = self.dense2(linear1_output)\n",
        "\n",
        "        return linear1_output\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def forward(batch, model):\n",
        "    feed_dict = {\n",
        "        'input_ids': batch['input_ids'].to(DEVICE),\n",
        "        'token_type_ids': batch['token_type_ids'].to(DEVICE),\n",
        "        'attention_mask': batch['attention_mask'].to(DEVICE),\n",
        "    }\n",
        "    # feed_dict = {\n",
        "    #     'input_ids': batch['input_ids'].to(DEVICE),\n",
        "    #     'token_type_ids': batch['token_type_ids'].to(DEVICE),\n",
        "    #     'attention_mask': batch['attention_mask'].to(DEVICE),\n",
        "    # }    \n",
        "    outputs = model(feed_dict)\n",
        "    outputs = F.log_softmax(outputs, dim=1)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "def validate(model, dataloader):\n",
        "    predictions, targets = [], []\n",
        "    for batch in dataloader:\n",
        "        target = batch['labels']\n",
        "        with torch.no_grad():\n",
        "            logits = forward(batch, model)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label = target.to('cpu').numpy()        \n",
        "        predictions.append(logits)\n",
        "        targets.append(label)\n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "    flat_targets = [item for sublist in targets for item in sublist]\n",
        "    return classification_report(flat_targets, flat_predictions)\n",
        "\n",
        "def reset_weights(m):\n",
        "    for layer in m.children():\n",
        "        if hasattr(layer, 'reset_parameters'):\n",
        "            print(f'Reset trainable parameters of layer = {layer}')\n",
        "            layer.reset_parameters()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA61MKDvGuCj"
      },
      "source": [
        "## Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "60f6110e0b4949c4910099a6c045762b",
            "3819806d9b7f48b6a3ba9a2dc884faad",
            "ec376cbe84c941e3aa00212abd5f88f1",
            "16aa11fd18424033ac3a45e759da6cdc",
            "1c43c7b0d42749829cc2d6f3138e7b71",
            "21f31a2f19f74622aa51d30f701db03f",
            "7b1882c24a144d3d8b73662e3339094e",
            "9078f1a2ace3448fb2fc55d4ea63196e",
            "1757e054198e40a0bd457032e3ca427a",
            "5ecd85f800fa49f89a390ae5c588306f",
            "73da7276eb484ae3b0aa88244c865f36"
          ]
        },
        "id": "voXHyVJmYIiG",
        "outputId": "778c2fa9-8094-4f4c-b370-2be27d4a7188"
      },
      "source": [
        "model = CustomBERTweet()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60f6110e0b4949c4910099a6c045762b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/543M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOj_5En0HAa9"
      },
      "source": [
        "## Check model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpKnFaGuG1Gb",
        "outputId": "67b79429-0062-4694-802a-fb5017624a49"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "print(f'The BERT model has {len(params):} different named parameters.\\n')\n",
        "print('==== Embedding Layer ====\\n')\n",
        "for p in params[0:5]:\n",
        "    print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "for p in params[5:21]:\n",
        "    print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "for p in params[-12:]:\n",
        "    print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bertweet.embeddings.word_embeddings.weight              (64001, 768)\n",
            "bertweet.embeddings.position_embeddings.weight            (130, 768)\n",
            "bertweet.embeddings.token_type_embeddings.weight            (1, 768)\n",
            "bertweet.embeddings.LayerNorm.weight                          (768,)\n",
            "bertweet.embeddings.LayerNorm.bias                            (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bertweet.encoder.layer.0.attention.self.query.weight      (768, 768)\n",
            "bertweet.encoder.layer.0.attention.self.query.bias            (768,)\n",
            "bertweet.encoder.layer.0.attention.self.key.weight        (768, 768)\n",
            "bertweet.encoder.layer.0.attention.self.key.bias              (768,)\n",
            "bertweet.encoder.layer.0.attention.self.value.weight      (768, 768)\n",
            "bertweet.encoder.layer.0.attention.self.value.bias            (768,)\n",
            "bertweet.encoder.layer.0.attention.output.dense.weight    (768, 768)\n",
            "bertweet.encoder.layer.0.attention.output.dense.bias          (768,)\n",
            "bertweet.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
            "bertweet.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
            "bertweet.encoder.layer.0.intermediate.dense.weight       (3072, 768)\n",
            "bertweet.encoder.layer.0.intermediate.dense.bias             (3072,)\n",
            "bertweet.encoder.layer.0.output.dense.weight             (768, 3072)\n",
            "bertweet.encoder.layer.0.output.dense.bias                    (768,)\n",
            "bertweet.encoder.layer.0.output.LayerNorm.weight              (768,)\n",
            "bertweet.encoder.layer.0.output.LayerNorm.bias                (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bertweet.encoder.layer.11.attention.output.LayerNorm.weight       (768,)\n",
            "bertweet.encoder.layer.11.attention.output.LayerNorm.bias       (768,)\n",
            "bertweet.encoder.layer.11.intermediate.dense.weight      (3072, 768)\n",
            "bertweet.encoder.layer.11.intermediate.dense.bias            (3072,)\n",
            "bertweet.encoder.layer.11.output.dense.weight            (768, 3072)\n",
            "bertweet.encoder.layer.11.output.dense.bias                   (768,)\n",
            "bertweet.encoder.layer.11.output.LayerNorm.weight             (768,)\n",
            "bertweet.encoder.layer.11.output.LayerNorm.bias               (768,)\n",
            "bertweet.pooler.dense.weight                              (768, 768)\n",
            "bertweet.pooler.dense.bias                                    (768,)\n",
            "dense1.weight                                               (2, 768)\n",
            "dense1.bias                                                     (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c48dAZ7BSaf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8354b28d-f8d9-4f60-beb0-dd86e7d06b12"
      },
      "source": [
        "model.to(torch.device('cuda'))\n",
        "print(validate(model, test_dataloader))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.58      0.63       529\n",
            "           1       0.32      0.44      0.37       240\n",
            "\n",
            "    accuracy                           0.54       769\n",
            "   macro avg       0.51      0.51      0.50       769\n",
            "weighted avg       0.58      0.54      0.55       769\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzNQK9-3Lh2w"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oasaOhW3yW2Y"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# for k-fold\n",
        "# Configuration options\n",
        "k_folds = 5\n",
        "num_epochs = 1\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# For fold results\n",
        "results = {}\n",
        "\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        " # Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
        "# use raw_dataset"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C536AVuWCQTm",
        "outputId": "8db7c15e-4fb0-40e0-c9b6-e8167486a579"
      },
      "source": [
        "EPOCHS = 4\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 20,\n",
        "                                            num_training_steps = total_steps)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "model.to(DEVICE)\n",
        "start = time.time()\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(raw_dataset)):    \n",
        "    # Print\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "    \n",
        "    # Sample elements randomly from a given list of ids, no replacement.\n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "    \n",
        "    # Define data loaders for training and testing data in this fold\n",
        "    # train_dataloader = torch.utils.data.DataLoader(\n",
        "    #                     dataset, \n",
        "    #                     batch_size=10, sampler=train_subsampler)\n",
        "    # test_dataloader = torch.utils.data.DataLoader(\n",
        "    #                     dataset,\n",
        "    #                     batch_size=10, sampler=test_subsampler)\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "            raw_dataset,\n",
        "            sampler = train_subsampler, # RandomSampler(raw_dataset),\n",
        "            batch_size = BATCH_SIZE\n",
        "    )\n",
        "    test_dataloader = DataLoader(\n",
        "            raw_dataset,\n",
        "            sampler = test_subsampler, # RandomSampler(raw_dataset),\n",
        "            batch_size = BATCH_SIZE\n",
        "    )\n",
        "    \n",
        "    print('Data train:')\n",
        "    it = iter(train_dataloader)\n",
        "    first = next(it)\n",
        "    print(first)\n",
        "\n",
        "    print('Data test:')\n",
        "    it = iter(test_dataloader)\n",
        "    first = next(it)\n",
        "    print(first)\n",
        "\n",
        "    # Init the neural network\n",
        "    #network = SimpleConvNet()\n",
        "    \n",
        "    # Initialize optimizer\n",
        "    #optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
        "    model.apply(reset_weights)\n",
        "\n",
        "    for epoch in range(0, EPOCHS):\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "        print(f'======== Epoch {epoch+1} / {EPOCHS} ========')\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            if step % 50 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - start)\n",
        "                print(f'\\tBatch {step:>5,}  of  {len(train_dataloader):>5,}.    Elapsed: {elapsed}.')\n",
        "                # print(f'\\tloss: {loss.item()}')\n",
        "            optimizer.zero_grad()\n",
        "            outputs = forward(batch, model)\n",
        "            target = batch['labels'].to(DEVICE)\n",
        "            model.zero_grad()\n",
        "            loss = loss_func(outputs, target)\n",
        "            total_train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        \n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "        training_time = format_time(time.time() - start)\n",
        "        print(f'\\tAverage training loss: {avg_train_loss:.2f}')\n",
        "        print(f'\\tTraining epoch took: {training_time}')\n",
        "        model.eval()\n",
        "        report = validate(model, test_dataloader)\n",
        "        print(f'======== Validation report {epoch+1} / {EPOCHS} ========')\n",
        "        print(report)\n",
        "\n",
        "    print('======= fold ')\n",
        "    model.eval()\n",
        "    report = validate(model, test_dataloader)\n",
        "    print(report)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n",
            "Data train:\n",
            "{'input_ids': tensor([[    0,  5238,  2091,  ...,     1,     1,     1],\n",
            "        [    0,   250,   111,  ..., 33010,  1610,     2],\n",
            "        [    0,   918,    54,  ..., 27185,  9989,     2],\n",
            "        ...,\n",
            "        [    0,  5238,  4712,  ...,     1,     1,     1],\n",
            "        [    0,  5238,   684,  ...,     1,     1,     1],\n",
            "        [    0,    54,   413,  ...,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0])}\n",
            "Data test:\n",
            "{'input_ids': tensor([[    0,   104, 10483,  ..., 10108, 62060,     2],\n",
            "        [    0,  5238, 17521,  ...,  5238,  3157,     2],\n",
            "        [    0, 13225,    30,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,  6865,   705,  ...,     1,     1,     1],\n",
            "        [    0,    37,    70,  ...,     1,     1,     1],\n",
            "        [    0,   165,    17,  ...,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])}\n",
            "Reset trainable parameters of layer = Embedding(64001, 768, padding_idx=1)\n",
            "Reset trainable parameters of layer = Embedding(130, 768, padding_idx=1)\n",
            "Reset trainable parameters of layer = Embedding(1, 768)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=2, bias=True)\n",
            "======== Epoch 1 / 4 ========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tBatch    50  of    154.    Elapsed: 0:00:04.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:08.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:12.\n",
            "\tAverage training loss: 0.67\n",
            "\tTraining epoch took: 0:00:12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Validation report 1 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      1.00      0.79       404\n",
            "           1       0.00      0.00      0.00       211\n",
            "\n",
            "    accuracy                           0.66       615\n",
            "   macro avg       0.33      0.50      0.40       615\n",
            "weighted avg       0.43      0.66      0.52       615\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:17.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:21.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:25.\n",
            "\tAverage training loss: 0.67\n",
            "\tTraining epoch took: 0:00:25\n",
            "======== Validation report 2 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      1.00      0.79       404\n",
            "           1       0.00      0.00      0.00       211\n",
            "\n",
            "    accuracy                           0.66       615\n",
            "   macro avg       0.33      0.50      0.40       615\n",
            "weighted avg       0.43      0.66      0.52       615\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:30.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:34.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:37.\n",
            "\tAverage training loss: 0.67\n",
            "\tTraining epoch took: 0:00:38\n",
            "======== Validation report 3 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      1.00      0.79       404\n",
            "           1       0.00      0.00      0.00       211\n",
            "\n",
            "    accuracy                           0.66       615\n",
            "   macro avg       0.33      0.50      0.40       615\n",
            "weighted avg       0.43      0.66      0.52       615\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:42.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:46.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:50.\n",
            "\tAverage training loss: 0.66\n",
            "\tTraining epoch took: 0:00:51\n",
            "======== Validation report 4 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      1.00      0.79       404\n",
            "           1       0.00      0.00      0.00       211\n",
            "\n",
            "    accuracy                           0.66       615\n",
            "   macro avg       0.33      0.50      0.40       615\n",
            "weighted avg       0.43      0.66      0.52       615\n",
            "\n",
            "======= fold \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      1.00      0.79       404\n",
            "           1       0.00      0.00      0.00       211\n",
            "\n",
            "    accuracy                           0.66       615\n",
            "   macro avg       0.33      0.50      0.40       615\n",
            "weighted avg       0.43      0.66      0.52       615\n",
            "\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Data train:\n",
            "{'input_ids': tensor([[    0,  5238, 18216,  ...,     1,     1,     1],\n",
            "        [    0,  5238, 20218,  ...,     1,     1,     1],\n",
            "        [    0,  1085,  1455,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0, 47955,  1360,  ...,     1,     1,     1],\n",
            "        [    0,  4543,    20,  ...,     1,     1,     1],\n",
            "        [    0,  1806,  4491,  ...,  3411,   472,     2]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1])}\n",
            "Data test:\n",
            "{'input_ids': tensor([[    0,   281,    99,  ...,  8232,  5286,     2],\n",
            "        [    0,   125,    14,  ...,  8798,     3,     2],\n",
            "        [    0, 62075, 50791,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,  5238,   686,  ..., 41612,    67,     2],\n",
            "        [    0,  5238,  2644,  ...,     1,     1,     1],\n",
            "        [    0, 54290,    13,  ...,   771,   641,     2]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0])}\n",
            "Reset trainable parameters of layer = Embedding(64001, 768, padding_idx=1)\n",
            "Reset trainable parameters of layer = Embedding(130, 768, padding_idx=1)\n",
            "Reset trainable parameters of layer = Embedding(1, 768)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=2, bias=True)\n",
            "======== Epoch 1 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:56.\n",
            "\tBatch   100  of    154.    Elapsed: 0:01:00.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:04.\n",
            "\tAverage training loss: 0.67\n",
            "\tTraining epoch took: 0:01:04\n",
            "======== Validation report 1 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       388\n",
            "           1       0.00      0.00      0.00       227\n",
            "\n",
            "    accuracy                           0.63       615\n",
            "   macro avg       0.32      0.50      0.39       615\n",
            "weighted avg       0.40      0.63      0.49       615\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:01:09.\n",
            "\tBatch   100  of    154.    Elapsed: 0:01:13.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:17.\n",
            "\tAverage training loss: 0.66\n",
            "\tTraining epoch took: 0:01:17\n",
            "======== Validation report 2 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       388\n",
            "           1       0.00      0.00      0.00       227\n",
            "\n",
            "    accuracy                           0.63       615\n",
            "   macro avg       0.32      0.50      0.39       615\n",
            "weighted avg       0.40      0.63      0.49       615\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:01:22.\n",
            "\tBatch   100  of    154.    Elapsed: 0:01:26.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:30.\n",
            "\tAverage training loss: 0.66\n",
            "\tTraining epoch took: 0:01:30\n",
            "======== Validation report 3 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       388\n",
            "           1       0.00      0.00      0.00       227\n",
            "\n",
            "    accuracy                           0.63       615\n",
            "   macro avg       0.32      0.50      0.39       615\n",
            "weighted avg       0.40      0.63      0.49       615\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:01:35.\n",
            "\tBatch   100  of    154.    Elapsed: 0:01:39.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:43.\n",
            "\tAverage training loss: 0.66\n",
            "\tTraining epoch took: 0:01:43\n",
            "======== Validation report 4 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       388\n",
            "           1       0.00      0.00      0.00       227\n",
            "\n",
            "    accuracy                           0.63       615\n",
            "   macro avg       0.32      0.50      0.39       615\n",
            "weighted avg       0.40      0.63      0.49       615\n",
            "\n",
            "======= fold \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       388\n",
            "           1       0.00      0.00      0.00       227\n",
            "\n",
            "    accuracy                           0.63       615\n",
            "   macro avg       0.32      0.50      0.39       615\n",
            "weighted avg       0.40      0.63      0.49       615\n",
            "\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Data train:\n",
            "{'input_ids': tensor([[    0,  1903, 14484,  ...,     1,     1,     1],\n",
            "        [    0,  3348,    11,  ...,     7,     8,     2],\n",
            "        [    0,  2276,  1562,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0, 45308,     9,  ...,     1,     1,     1],\n",
            "        [    0,  5238,   581,  ...,     1,     1,     1],\n",
            "        [    0,  5238, 27478,  ...,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0])}\n",
            "Data test:\n",
            "{'input_ids': tensor([[   0, 2206,   87,  ...,    1,    1,    1],\n",
            "        [   0, 5238, 3418,  ...,    1,    1,    1],\n",
            "        [   0, 5238,  521,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   0, 5238, 6965,  ...,   35,   48,    2],\n",
            "        [   0,  326,   17,  ...,    1,    1,    1],\n",
            "        [   0,  959,   32,  ...,    1,    1,    1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0])}\n",
            "Reset trainable parameters of layer = Embedding(64001, 768, padding_idx=1)\n",
            "Reset trainable parameters of layer = Embedding(130, 768, padding_idx=1)\n",
            "Reset trainable parameters of layer = Embedding(1, 768)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=2, bias=True)\n",
            "======== Epoch 1 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:01:49.\n",
            "\tBatch   100  of    154.    Elapsed: 0:01:52.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:56.\n",
            "\tAverage training loss: 0.75\n",
            "\tTraining epoch took: 0:01:57\n",
            "======== Validation report 1 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       392\n",
            "           1       0.36      1.00      0.53       223\n",
            "\n",
            "    accuracy                           0.36       615\n",
            "   macro avg       0.18      0.50      0.27       615\n",
            "weighted avg       0.13      0.36      0.19       615\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:02:01.\n",
            "\tBatch   100  of    154.    Elapsed: 0:02:05.\n",
            "\tBatch   150  of    154.    Elapsed: 0:02:09.\n",
            "\tAverage training loss: 0.75\n",
            "\tTraining epoch took: 0:02:09\n",
            "======== Validation report 2 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       392\n",
            "           1       0.36      1.00      0.53       223\n",
            "\n",
            "    accuracy                           0.36       615\n",
            "   macro avg       0.18      0.50      0.27       615\n",
            "weighted avg       0.13      0.36      0.19       615\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:02:14.\n",
            "\tBatch   100  of    154.    Elapsed: 0:02:18.\n",
            "\tBatch   150  of    154.    Elapsed: 0:02:22.\n",
            "\tAverage training loss: 0.75\n",
            "\tTraining epoch took: 0:02:22\n",
            "======== Validation report 3 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       392\n",
            "           1       0.36      1.00      0.53       223\n",
            "\n",
            "    accuracy                           0.36       615\n",
            "   macro avg       0.18      0.50      0.27       615\n",
            "weighted avg       0.13      0.36      0.19       615\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:02:27.\n",
            "\tBatch   100  of    154.    Elapsed: 0:02:31.\n",
            "\tBatch   150  of    154.    Elapsed: 0:02:35.\n",
            "\tAverage training loss: 0.75\n",
            "\tTraining epoch took: 0:02:35\n",
            "======== Validation report 4 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       392\n",
            "           1       0.36      1.00      0.53       223\n",
            "\n",
            "    accuracy                           0.36       615\n",
            "   macro avg       0.18      0.50      0.27       615\n",
            "weighted avg       0.13      0.36      0.19       615\n",
            "\n",
            "======= fold \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       392\n",
            "           1       0.36      1.00      0.53       223\n",
            "\n",
            "    accuracy                           0.36       615\n",
            "   macro avg       0.18      0.50      0.27       615\n",
            "weighted avg       0.13      0.36      0.19       615\n",
            "\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Data train:\n",
            "{'input_ids': tensor([[    0,   192,   638,  ...,     1,     1,     1],\n",
            "        [    0,    92,   145,  ...,     1,     1,     1],\n",
            "        [    0,  5238,  1787,  ...,    12, 27185,     2],\n",
            "        ...,\n",
            "        [    0,   203,   158,  ...,     1,     1,     1],\n",
            "        [    0,  5238,  9172,  ...,    79,   116,     2],\n",
            "        [    0, 21759,  6627,  ...,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0])}\n",
            "Data test:\n",
            "{'input_ids': tensor([[    0,  5238,   527,  ...,     1,     1,     1],\n",
            "        [    0,  5238, 53270,  ...,     1,     1,     1],\n",
            "        [    0,    85, 61243,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0, 62075, 62075,  ..., 11412,  1751,     2],\n",
            "        [    0,  3246,  3068,  ...,  1513,     2,     1],\n",
            "        [    0,   500,  7643,  ...,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0])}\n",
            "Reset trainable parameters of layer = Embedding(64001, 768, padding_idx=1)\n",
            "Reset trainable parameters of layer = Embedding(130, 768, padding_idx=1)\n",
            "Reset trainable parameters of layer = Embedding(1, 768)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=2, bias=True)\n",
            "======== Epoch 1 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:02:41.\n",
            "\tBatch   100  of    154.    Elapsed: 0:02:45.\n",
            "\tBatch   150  of    154.    Elapsed: 0:02:49.\n",
            "\tAverage training loss: 0.66\n",
            "\tTraining epoch took: 0:02:49\n",
            "======== Validation report 1 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       385\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.63       615\n",
            "   macro avg       0.31      0.50      0.39       615\n",
            "weighted avg       0.39      0.63      0.48       615\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:02:54.\n",
            "\tBatch   100  of    154.    Elapsed: 0:02:58.\n",
            "\tBatch   150  of    154.    Elapsed: 0:03:02.\n",
            "\tAverage training loss: 0.67\n",
            "\tTraining epoch took: 0:03:02\n",
            "======== Validation report 2 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       385\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.63       615\n",
            "   macro avg       0.31      0.50      0.39       615\n",
            "weighted avg       0.39      0.63      0.48       615\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:03:07.\n",
            "\tBatch   100  of    154.    Elapsed: 0:03:10.\n",
            "\tBatch   150  of    154.    Elapsed: 0:03:14.\n",
            "\tAverage training loss: 0.66\n",
            "\tTraining epoch took: 0:03:15\n",
            "======== Validation report 3 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       385\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.63       615\n",
            "   macro avg       0.31      0.50      0.39       615\n",
            "weighted avg       0.39      0.63      0.48       615\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:03:19.\n",
            "\tBatch   100  of    154.    Elapsed: 0:03:23.\n",
            "\tBatch   150  of    154.    Elapsed: 0:03:27.\n",
            "\tAverage training loss: 0.67\n",
            "\tTraining epoch took: 0:03:28\n",
            "======== Validation report 4 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       385\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.63       615\n",
            "   macro avg       0.31      0.50      0.39       615\n",
            "weighted avg       0.39      0.63      0.48       615\n",
            "\n",
            "======= fold \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       385\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.63       615\n",
            "   macro avg       0.31      0.50      0.39       615\n",
            "weighted avg       0.39      0.63      0.48       615\n",
            "\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Data train:\n",
            "{'input_ids': tensor([[    0,  5238, 12076,  ...,     1,     1,     1],\n",
            "        [    0,  5238,   684,  ...,     4,  6627,     2],\n",
            "        [    0,   490,    48,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,  1085, 58297,  ...,     1,     1,     1],\n",
            "        [    0,  5238,  1059,  ...,     1,     1,     1],\n",
            "        [    0,   269,  1926,  ...,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "Data test:\n",
            "{'input_ids': tensor([[    0,  5238,  8001,  ...,  5910, 62060,     2],\n",
            "        [    0,   126,    17,  ...,     2,     1,     1],\n",
            "        [    0,   165,    11,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,  5238,  2136,  ...,     1,     1,     1],\n",
            "        [    0, 25869,  5910,  ...,     1,     1,     1],\n",
            "        [    0,  5238,  1468,  ...,     1,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0])}\n",
            "Reset trainable parameters of layer = Embedding(64001, 768, padding_idx=1)\n",
            "Reset trainable parameters of layer = Embedding(130, 768, padding_idx=1)\n",
            "Reset trainable parameters of layer = Embedding(1, 768)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=3072, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=3072, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=768, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=768, out_features=2, bias=True)\n",
            "======== Epoch 1 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:03:33.\n",
            "\tBatch   100  of    154.    Elapsed: 0:03:37.\n",
            "\tBatch   150  of    154.    Elapsed: 0:03:41.\n",
            "\tAverage training loss: 0.83\n",
            "\tTraining epoch took: 0:03:41\n",
            "======== Validation report 1 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       403\n",
            "           1       0.34      1.00      0.51       211\n",
            "\n",
            "    accuracy                           0.34       614\n",
            "   macro avg       0.17      0.50      0.26       614\n",
            "weighted avg       0.12      0.34      0.18       614\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:03:46.\n",
            "\tBatch   100  of    154.    Elapsed: 0:03:50.\n",
            "\tBatch   150  of    154.    Elapsed: 0:03:54.\n",
            "\tAverage training loss: 0.83\n",
            "\tTraining epoch took: 0:03:54\n",
            "======== Validation report 2 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       403\n",
            "           1       0.34      1.00      0.51       211\n",
            "\n",
            "    accuracy                           0.34       614\n",
            "   macro avg       0.17      0.50      0.26       614\n",
            "weighted avg       0.12      0.34      0.18       614\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:03:59.\n",
            "\tBatch   100  of    154.    Elapsed: 0:04:03.\n",
            "\tBatch   150  of    154.    Elapsed: 0:04:07.\n",
            "\tAverage training loss: 0.84\n",
            "\tTraining epoch took: 0:04:07\n",
            "======== Validation report 3 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       403\n",
            "           1       0.34      1.00      0.51       211\n",
            "\n",
            "    accuracy                           0.34       614\n",
            "   macro avg       0.17      0.50      0.26       614\n",
            "weighted avg       0.12      0.34      0.18       614\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:04:12.\n",
            "\tBatch   100  of    154.    Elapsed: 0:04:16.\n",
            "\tBatch   150  of    154.    Elapsed: 0:04:20.\n",
            "\tAverage training loss: 0.83\n",
            "\tTraining epoch took: 0:04:20\n",
            "======== Validation report 4 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       403\n",
            "           1       0.34      1.00      0.51       211\n",
            "\n",
            "    accuracy                           0.34       614\n",
            "   macro avg       0.17      0.50      0.26       614\n",
            "weighted avg       0.12      0.34      0.18       614\n",
            "\n",
            "======= fold \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       403\n",
            "           1       0.34      1.00      0.51       211\n",
            "\n",
            "    accuracy                           0.34       614\n",
            "   macro avg       0.17      0.50      0.26       614\n",
            "weighted avg       0.12      0.34      0.18       614\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJPGoPPuHlSW"
      },
      "source": [
        "# custom_model = CustomLaBSE()\n",
        "# custom_model.eval()\n",
        "# encoded = tokenizer(train_texts[:10], padding=True, truncation=True, max_length=64, return_tensors='pt')\n",
        "# with torch.no_grad():\n",
        "  # outputs = custom_model.forward(encoded)\n",
        "  # labse_output = custom_model.labse(**encoded)\n",
        "# dense1 = nn.Linear(768, 256)\n",
        "# dense2 = nn.Linear(256, 2)\n",
        "# linear1_output = dense1(labse_output.pooler_output)\n",
        "# linear2_output = dense2(linear1_output)\n",
        "# crit = nn.CrossEntropyLoss()\n",
        "# sm = F.log_softmax(outputs, dim=1)\n",
        "# target = torch.tensor(train_labels[:10])\n",
        "# crit(sm, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgxVDjRZFOxO",
        "outputId": "91eaddfb-b743-43ff-fa7e-7be4f0b04845"
      },
      "source": [
        "model.eval()\n",
        "report = validate(model, test_dataloader)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.91      0.88       529\n",
            "           1       0.77      0.68      0.72       240\n",
            "\n",
            "    accuracy                           0.84       769\n",
            "   macro avg       0.82      0.80      0.80       769\n",
            "weighted avg       0.83      0.84      0.83       769\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-kQ0VDXrsP-"
      },
      "source": [
        "#Garbage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "XDYZ54M5iCqU",
        "outputId": "2f6081f5-fddd-46dc-cdc8-320d751fe1fd"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "OUTPUT_DIR = os.path.join(ROOT_DIR, 'labse_ft_results')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = OUTPUT_DIR,          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=0,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir=os.path.join(OUTPUT_DIR, 'logs'),            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=custom_model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset             # evaluation dataset\n",
        ")\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 3074\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 579\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-f4c3606a0c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m             \u001b[0;31m# evaluation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1278\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1803\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'input_ids'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqnZ9tL1h3si"
      },
      "source": [
        "max_len = 64\n",
        "row = train_df.iloc[0]\n",
        "texts = row.text\n",
        "encoded_input = tokenizer([texts, texts], padding=True, truncation=True, max_length=max_len, return_tensors='pt').to(device=DEVICE)\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "embeddings = model_output.pooler_output\n",
        "embeddings = torch.nn.functional.normalize(embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSGB8qxLZhKR",
        "outputId": "90210d94-4ed9-4c1a-915b-ce693d926df0"
      },
      "source": [
        "model_output.pooler_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__jZ2E4GfMch"
      },
      "source": [
        "train_embedings = text_encoder(train_texts, model, tokenizer, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90XN-tYKmgGk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkqo7q2ohNr7"
      },
      "source": [
        "sentences = [\"Hello World\"]\n",
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=max_len, return_tensors='pt').to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "embeddings = model_output.pooler_output\n",
        "embeddings = torch.nn.functional.normalize(embeddings)\n",
        "# print(embeddings[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf87TF-3um1S",
        "outputId": "ccbd18ec-f93e-44f1-856d-bf7a1cb99522"
      },
      "source": [
        "model_output.pooler_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFaqzhP4xDh_",
        "outputId": "31272612-dc58-4edd-df7f-78c47ad35ab1"
      },
      "source": [
        "model.parameters()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f24480df4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3qEzlo2fHVc",
        "outputId": "4d34e4fd-c9e6-4e61-b49b-2638c6b1be0b"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCmXOdSXUkIY"
      },
      "source": [
        "\n",
        "\n",
        "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
        "val_dataset = IMDbDataset(val_encodings, val_labels)\n",
        "test_dataset = IMDbDataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2alm0UHwp_L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehujnukbAoWe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}