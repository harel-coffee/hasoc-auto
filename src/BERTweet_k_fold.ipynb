{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTweet_k-fold.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k-kQ0VDXrsP-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38079533486b40c1891e892668d4e702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f4c619e2116145b9b6d6c2baeea7e226",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5aab8edfdd241a4a3781371f96f8bf8",
              "IPY_MODEL_b92dcf3944344fc0ab8a80ac103c7acb",
              "IPY_MODEL_a050b43310594e36b036079e46d1a00c"
            ]
          }
        },
        "f4c619e2116145b9b6d6c2baeea7e226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5aab8edfdd241a4a3781371f96f8bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c318bc0e23e74948874818f8dc3e99d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c825f227a1c44a4b975ef807b1145ab"
          }
        },
        "b92dcf3944344fc0ab8a80ac103c7acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60810779feb24eb0aaba94b851b2b76a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 558,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 558,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9eb60d235ed94c05ac98224630f4e254"
          }
        },
        "a050b43310594e36b036079e46d1a00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_970bfa694caf49d8affd666d843e8a9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 558/558 [00:00&lt;00:00, 15.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f5a89e3ff6246fe8d25bed295e229de"
          }
        },
        "c318bc0e23e74948874818f8dc3e99d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c825f227a1c44a4b975ef807b1145ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60810779feb24eb0aaba94b851b2b76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9eb60d235ed94c05ac98224630f4e254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "970bfa694caf49d8affd666d843e8a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f5a89e3ff6246fe8d25bed295e229de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7040f0703ba1427db44b16c3aba59aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_951b034084894a8f8f70cde5e6700836",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b280bd8a9b841a5863b1ef4f3ac8043",
              "IPY_MODEL_262a6b7df4534a098f8ce4f727070e82",
              "IPY_MODEL_b08b1b51e52a4f638fe5a73dd82865e4"
            ]
          }
        },
        "951b034084894a8f8f70cde5e6700836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b280bd8a9b841a5863b1ef4f3ac8043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f471c962a0d44065be728a8f151b52f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_224f2e50c06f42d6bcf3cda219260b59"
          }
        },
        "262a6b7df4534a098f8ce4f727070e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3869813380bc4f50a8c7c3a414e4cbee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 843438,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 843438,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a04752151b7943e89f4b96bc303e0cf5"
          }
        },
        "b08b1b51e52a4f638fe5a73dd82865e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_16fe68b462d4480cacf801fdeeea84eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 843k/843k [00:00&lt;00:00, 1.79MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfa140899362466c84b27901a5f38396"
          }
        },
        "f471c962a0d44065be728a8f151b52f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "224f2e50c06f42d6bcf3cda219260b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3869813380bc4f50a8c7c3a414e4cbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a04752151b7943e89f4b96bc303e0cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16fe68b462d4480cacf801fdeeea84eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfa140899362466c84b27901a5f38396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20d0db058f6749b9a06a55395e102dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4993178d24b47f8a7bb60eb2b99d5fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce306d245e374057a482e028fab828cf",
              "IPY_MODEL_4a5f8e5b217b438fa18cf58cb3b6851b",
              "IPY_MODEL_3cb3cbc18f5948efad7c27bada2a3f66"
            ]
          }
        },
        "d4993178d24b47f8a7bb60eb2b99d5fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce306d245e374057a482e028fab828cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8dc01249aed94019937ec6e0d589734c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f5aadf2eae240d8b6760cef05324f6c"
          }
        },
        "4a5f8e5b217b438fa18cf58cb3b6851b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_40cfc11365ba48d1ae32045da797773b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1078931,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1078931,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_386c6f2ee3e246d1aed58787314bc2d8"
          }
        },
        "3cb3cbc18f5948efad7c27bada2a3f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_05ec4e63a446459587981f699973a46d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.08M/1.08M [00:00&lt;00:00, 4.66MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5852163a9b93419c8280adf78c400890"
          }
        },
        "8dc01249aed94019937ec6e0d589734c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f5aadf2eae240d8b6760cef05324f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40cfc11365ba48d1ae32045da797773b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "386c6f2ee3e246d1aed58787314bc2d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05ec4e63a446459587981f699973a46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5852163a9b93419c8280adf78c400890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ixomaxip/nasoc/blob/master/src/BERTweet_k_fold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8SipYd8wXSs",
        "outputId": "cad36006-908c-4dd4-a278-94995c523351"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 11 15:00:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ToLnryTqUg-"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install nltk emoji\n",
        "!pip install tweet-preprocessor\n",
        "\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "\n",
        "!wget https://hasocfire.github.io/hasoc/2021/files/en_Hasoc2021_train.zip\n",
        "!unzip -P hasoc2021_en en_Hasoc2021_train.zip\n",
        "!ls\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVRtn1TZSxGK",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARQ02wGdHGXR",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# !rm -rf /root/.ssh\n",
        "# !mkdir /root/.ssh\n",
        "# # !tar -xvzf ssh.tar.gz -C /root/.ssh && rm -rf ssh.tar.gz && chmod 700 /root/.ssh\n",
        "# !tar -xvzf ssh.tar.gz -C /root/.ssh && rm -rf ssh.tar.gz\n",
        "# !ssh-keyscan -t rsa github.com >> /root/.ssh/known_hosts\n",
        "\n",
        "# !git config --global user.email 'ixomaxip@gmail.com'\n",
        "# !git config --global user.user 'ixomaxip'\n",
        "# !ssh -T git@github.com\n",
        "\n",
        "# !git clone git@github.com:ixomaxip/nasoc.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3QnjK3TdjmO"
      },
      "source": [
        "# Custom BERTweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K18B6AOMH599"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import datetime\n",
        "import re\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "#constants and parameters\n",
        "seed = 42\n",
        "\n",
        "path_gdrive_saved = '/content/drive/My Drive/nasoc/bert_tuned.weights'\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "DOWNLOAD_DATASET = False\n",
        "\n",
        "# dataset\n",
        "\n",
        "raw_df = pd.read_csv('en_Hasoc2021_train.csv')\n",
        "\n",
        "raw_df['inputs'] = pd.Categorical(raw_df['task_1'])\n",
        "raw_df['inputs'] = raw_df.inputs.cat.codes\n",
        "\n",
        "raw_df['task_2_cat'] = pd.Categorical(raw_df['task_2'])\n",
        "raw_df['task_2_cat'] = raw_df.task_2_cat.cat.codes\n",
        "\n",
        "train_df, test_df = train_test_split(raw_df, test_size=0.2, random_state=seed)\n",
        "\n",
        "sr_train = train_df.groupby('task_1').count()['text']\n",
        "sr_test  = test_df.groupby('task_1').count()['text']\n",
        "\n",
        "tr_pr = sr_train['NOT']/sr_train['HOF']\n",
        "ts_pr = sr_test['NOT']/sr_test['HOF']\n",
        "\n",
        "#copied from https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)\n",
        "\n",
        "# copied from https://stackoverflow.com/questions/64719706/cleaning-twitter-data-pandas-python\n",
        "def cleaner(tweet):\n",
        "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
        "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
        "    #tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
        "    tweet = \" \".join(tweet.split())\n",
        "    tweet = remove_emojis(tweet)\n",
        "    #tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
        "    #     if w.lower() in words or not w.isalpha())\n",
        "    return tweet\n",
        "\n",
        "raw_df_tmp = raw_df.copy(True)\n",
        "train_df, test_df = train_test_split(raw_df_tmp, test_size=0.2, random_state=seed)\n",
        "#text = train_df.pop('text')#.map(lambda line: cleaner(line))\n",
        "#label = train_df.pop('inputs')\n",
        "\n",
        "#text_val = test_df.pop('text')#.map(lambda line: cleaner(line))\n",
        "#label_val = test_df.pop('inputs')\n",
        "\n",
        "#train_ds = tf.data.Dataset.from_tensor_slices((text.values, label.values))\n",
        "#val_ds = tf.data.Dataset.from_tensor_slices((text_val.values, label_val.values))\n",
        "\n",
        "#train_ds = train_ds.batch(batch_size=batch_size, drop_remainder=True)\n",
        "#val_ds = val_ds.batch(batch_size=batch_size, drop_remainder=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONcydGgGsaqt"
      },
      "source": [
        "import time, datetime\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F, Linear\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GubgnSZx4jcf"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "38079533486b40c1891e892668d4e702",
            "f4c619e2116145b9b6d6c2baeea7e226",
            "a5aab8edfdd241a4a3781371f96f8bf8",
            "b92dcf3944344fc0ab8a80ac103c7acb",
            "a050b43310594e36b036079e46d1a00c",
            "c318bc0e23e74948874818f8dc3e99d2",
            "2c825f227a1c44a4b975ef807b1145ab",
            "60810779feb24eb0aaba94b851b2b76a",
            "9eb60d235ed94c05ac98224630f4e254",
            "970bfa694caf49d8affd666d843e8a9c",
            "6f5a89e3ff6246fe8d25bed295e229de",
            "7040f0703ba1427db44b16c3aba59aca",
            "951b034084894a8f8f70cde5e6700836",
            "3b280bd8a9b841a5863b1ef4f3ac8043",
            "262a6b7df4534a098f8ce4f727070e82",
            "b08b1b51e52a4f638fe5a73dd82865e4",
            "f471c962a0d44065be728a8f151b52f5",
            "224f2e50c06f42d6bcf3cda219260b59",
            "3869813380bc4f50a8c7c3a414e4cbee",
            "a04752151b7943e89f4b96bc303e0cf5",
            "16fe68b462d4480cacf801fdeeea84eb",
            "dfa140899362466c84b27901a5f38396",
            "20d0db058f6749b9a06a55395e102dda",
            "d4993178d24b47f8a7bb60eb2b99d5fa",
            "ce306d245e374057a482e028fab828cf",
            "4a5f8e5b217b438fa18cf58cb3b6851b",
            "3cb3cbc18f5948efad7c27bada2a3f66",
            "8dc01249aed94019937ec6e0d589734c",
            "4f5aadf2eae240d8b6760cef05324f6c",
            "40cfc11365ba48d1ae32045da797773b",
            "386c6f2ee3e246d1aed58787314bc2d8",
            "05ec4e63a446459587981f699973a46d",
            "5852163a9b93419c8280adf78c400890"
          ]
        },
        "id": "ocg_xpB_hALs",
        "outputId": "0769bdd9-79f7-4f7b-eab4-fe81c382a8db"
      },
      "source": [
        "class HasocDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=64, return_tensors='pt')\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "#MODEL_NAME = \"cardiffnlp/twitter-roberta-base-hate\"\n",
        "MODEL_NAME = \"vinai/bertweet-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "train_dataset = HasocDataset(train_df['text'].to_list(), train_df['inputs'].to_list(), tokenizer)\n",
        "test_dataset = HasocDataset(test_df['text'].to_list(), test_df['inputs'].to_list(), tokenizer)\n",
        "\n",
        "raw_dataset = HasocDataset(raw_df['text'].to_list(), raw_df['inputs'].to_list(), tokenizer)\n",
        "\n",
        "BATCH_SIZE = 16\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38079533486b40c1891e892668d4e702",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/558 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7040f0703ba1427db44b16c3aba59aca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/843k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20d0db058f6749b9a06a55395e102dda",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMC2E1uJ4BDQ"
      },
      "source": [
        "# it = iter(test_dataloader)\n",
        "# first = next(it)\n",
        "\n",
        "# print(first)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iNBpJxQGhlc"
      },
      "source": [
        "## Customization class & auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wghRCjFwp5rT"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# DEVICE = torch.device('cpu')\n",
        "\n",
        "# Customization\n",
        "class CustomBERTweet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBERTweet, self).__init__()\n",
        "        self.bertweet = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        #self.cnn = nn.Conv1d(1, 768, 3)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.dense1 = nn.Linear(768, 2)\n",
        "        # self.dense2 = nn.Linear(256, 2)\n",
        "    \n",
        "    def forward(self, feed_dict):\n",
        "\n",
        "        bertweet_output = self.bertweet(**feed_dict)\n",
        "        drop_output = self.dropout(bertweet_output.pooler_output)\n",
        "        linear1_output = self.dense1(drop_output)\n",
        "        # linear2_output = self.dense2(linear1_output)\n",
        "\n",
        "        return linear1_output\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def forward(batch, model):\n",
        "    feed_dict = {\n",
        "        'input_ids': batch['input_ids'].to(DEVICE),\n",
        "        'token_type_ids': batch['token_type_ids'].to(DEVICE),\n",
        "        'attention_mask': batch['attention_mask'].to(DEVICE),\n",
        "    }\n",
        "    # feed_dict = {\n",
        "    #     'input_ids': batch['input_ids'].to(DEVICE),\n",
        "    #     'token_type_ids': batch['token_type_ids'].to(DEVICE),\n",
        "    #     'attention_mask': batch['attention_mask'].to(DEVICE),\n",
        "    # }    \n",
        "    outputs = model(feed_dict)\n",
        "    outputs = F.log_softmax(outputs, dim=1)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "def validate(model, dataloader, as_dict=False):\n",
        "    predictions, targets = [], []\n",
        "    for batch in dataloader:\n",
        "        target = batch['labels']\n",
        "        with torch.no_grad():\n",
        "            logits = forward(batch, model)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label = target.to('cpu').numpy()        \n",
        "        predictions.append(logits)\n",
        "        targets.append(label)\n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "    flat_targets = [item for sublist in targets for item in sublist]\n",
        "    return classification_report(flat_targets, flat_predictions, output_dict=as_dict)\n",
        "\n",
        "def reset_weights(m):\n",
        "    for layer in m.children():\n",
        "        if hasattr(layer, 'reset_parameters'):\n",
        "            #print(f'Reset trainable parameters of layer = {layer}')\n",
        "            layer.reset_parameters()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agXV9FD9BWAM"
      },
      "source": [
        "# del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA61MKDvGuCj"
      },
      "source": [
        "## Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voXHyVJmYIiG",
        "outputId": "a5563b22-0657-4453-b1d9-03082d1e842d"
      },
      "source": [
        "true_train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = BATCH_SIZE\n",
        ")\n",
        "true_test_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            sampler = RandomSampler(test_dataset),\n",
        "            batch_size = BATCH_SIZE\n",
        ")\n",
        "len(true_train_dataloader)\n",
        "\n",
        "#model = CustomBERTweet()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOj_5En0HAa9"
      },
      "source": [
        "## Check model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpKnFaGuG1Gb"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "print(f'The BERT model has {len(params):} different named parameters.\\n')\n",
        "print('==== Embedding Layer ====\\n')\n",
        "for p in params[0:5]:\n",
        "    print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "for p in params[5:21]:\n",
        "    print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "for p in params[-12:]:\n",
        "    print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c48dAZ7BSaf8"
      },
      "source": [
        "model.to(torch.device('cuda'))\n",
        "print(validate(model, test_dataloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzNQK9-3Lh2w"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oasaOhW3yW2Y"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "k_folds = 2\n",
        "EPOCHS = 1\n",
        "\n",
        "# For fold results\n",
        "results = {}\n",
        "\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPgMJUf6_A7x",
        "outputId": "29ec9d65-e377-43f7-8bfb-b55b841adc3e"
      },
      "source": [
        "# # model = CustomBERTweet()\n",
        "# # params = list(model.named_parameters())\n",
        "# # model.to(torch.device('cuda'))\n",
        "# # print(validate(model, test_dataloader))\n",
        "\n",
        "for fold, (train_ids_idx, test_ids_idx) in enumerate(kfold.split(train_dataset)):    \n",
        "    # Print\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "    \n",
        "#     # Sample elements randomly from a given list of ids, no replacement.\n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids_idx)\n",
        "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids_idx)\n",
        "    \n",
        "    # Define data loaders for training and testing data in this fold\n",
        "    k_fold_train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = train_subsampler,\n",
        "            batch_size = BATCH_SIZE\n",
        "    )\n",
        "    k_fold_test_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = test_subsampler,\n",
        "            batch_size = BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    model_kf = CustomBERTweet()\n",
        "\n",
        "    total_steps = len(k_fold_train_dataloader) * EPOCHS\n",
        "    optimizer = AdamW(model_kf.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                                num_warmup_steps = 20,\n",
        "                                                num_training_steps = total_steps)\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    model_kf.to(DEVICE)\n",
        "\n",
        "    #print(validate(model_kf, test_dataloader))\n",
        "\n",
        "    start = time.time()\n",
        "    for epoch in range(0, EPOCHS):\n",
        "        total_train_loss = 0\n",
        "        model_kf.train()\n",
        "        print(f'======== Epoch {epoch+1} / {EPOCHS} ========')\n",
        "        for step, batch in enumerate(k_fold_train_dataloader):\n",
        "            #print(f\"step: {step}\")\n",
        "            if step % 50 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - start)\n",
        "                print(f'\\tBatch {step:>5,}  of  {len(k_fold_train_dataloader):>5,}.    Elapsed: {elapsed}.')\n",
        "                # print(f'\\tloss: {loss.item()}')\n",
        "            optimizer.zero_grad()\n",
        "            outputs = forward(batch, model_kf)\n",
        "            target = batch['labels'].to(DEVICE)\n",
        "            model_kf.zero_grad()\n",
        "            loss = loss_func(outputs, target)\n",
        "            total_train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model_kf.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        \n",
        "        avg_train_loss = total_train_loss / len(k_fold_test_dataloader)\n",
        "        training_time = format_time(time.time() - start)\n",
        "        print(f'\\tAverage training loss: {avg_train_loss:.2f}')\n",
        "        print(f'\\tTraining epoch took: {training_time}')\n",
        "        model_kf.eval()\n",
        "        report = validate(model_kf, k_fold_test_dataloader)\n",
        "        print(f'======== Validation report {epoch+1} / {EPOCHS} ========')\n",
        "        print(report)\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(true_test_dataloader)\n",
        "    training_time = format_time(time.time() - start)\n",
        "    model_kf.eval()\n",
        "    report = validate(model_kf, true_test_dataloader)\n",
        "    print(f'======== fold {fold} validation ========')\n",
        "    print(report)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tBatch    50  of    154.    Elapsed: 0:00:07.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:13.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:20.\n",
            "\tAverage training loss: 2.13\n",
            "\tTraining epoch took: 0:00:20\n",
            "======== Validation report 1 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.95      0.84       398\n",
            "           1       0.82      0.43      0.56       217\n",
            "\n",
            "    accuracy                           0.77       615\n",
            "   macro avg       0.79      0.69      0.70       615\n",
            "weighted avg       0.78      0.77      0.74       615\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:28.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:34.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:41.\n",
            "\tAverage training loss: 1.58\n",
            "\tTraining epoch took: 0:00:41\n",
            "======== Validation report 2 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.93      0.85       398\n",
            "           1       0.81      0.55      0.66       217\n",
            "\n",
            "    accuracy                           0.80       615\n",
            "   macro avg       0.80      0.74      0.75       615\n",
            "weighted avg       0.80      0.80      0.78       615\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:49.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:56.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:02.\n",
            "\tAverage training loss: 1.16\n",
            "\tTraining epoch took: 0:01:03\n",
            "======== Validation report 3 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85       398\n",
            "           1       0.75      0.62      0.68       217\n",
            "\n",
            "    accuracy                           0.79       615\n",
            "   macro avg       0.78      0.75      0.76       615\n",
            "weighted avg       0.79      0.79      0.79       615\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:01:11.\n",
            "\tBatch   100  of    154.    Elapsed: 0:01:17.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:23.\n",
            "\tAverage training loss: 0.90\n",
            "\tTraining epoch took: 0:01:24\n",
            "======== Validation report 4 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       398\n",
            "           1       0.74      0.65      0.69       217\n",
            "\n",
            "    accuracy                           0.80       615\n",
            "   macro avg       0.78      0.76      0.77       615\n",
            "weighted avg       0.79      0.80      0.79       615\n",
            "\n",
            "======== fold 0 validation ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       529\n",
            "           1       0.72      0.67      0.69       240\n",
            "\n",
            "    accuracy                           0.82       769\n",
            "   macro avg       0.79      0.77      0.78       769\n",
            "weighted avg       0.81      0.82      0.81       769\n",
            "\n",
            "FOLD 1\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:06.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:13.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:19.\n",
            "\tAverage training loss: 2.21\n",
            "\tTraining epoch took: 0:00:20\n",
            "======== Validation report 1 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.85       388\n",
            "           1       0.76      0.68      0.72       227\n",
            "\n",
            "    accuracy                           0.80       615\n",
            "   macro avg       0.79      0.78      0.78       615\n",
            "weighted avg       0.80      0.80      0.80       615\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:28.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:34.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:41.\n",
            "\tAverage training loss: 1.74\n",
            "\tTraining epoch took: 0:00:41\n",
            "======== Validation report 2 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.95      0.85       388\n",
            "           1       0.86      0.51      0.64       227\n",
            "\n",
            "    accuracy                           0.79       615\n",
            "   macro avg       0.82      0.73      0.74       615\n",
            "weighted avg       0.80      0.79      0.77       615\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:49.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:56.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:02.\n",
            "\tAverage training loss: 1.36\n",
            "\tTraining epoch took: 0:01:03\n",
            "======== Validation report 3 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       388\n",
            "           1       0.79      0.68      0.73       227\n",
            "\n",
            "    accuracy                           0.82       615\n",
            "   macro avg       0.81      0.79      0.80       615\n",
            "weighted avg       0.82      0.82      0.81       615\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:01:10.\n",
            "\tBatch   100  of    154.    Elapsed: 0:01:17.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:23.\n",
            "\tAverage training loss: 1.11\n",
            "\tTraining epoch took: 0:01:24\n",
            "======== Validation report 4 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86       388\n",
            "           1       0.81      0.65      0.72       227\n",
            "\n",
            "    accuracy                           0.81       615\n",
            "   macro avg       0.81      0.78      0.79       615\n",
            "weighted avg       0.81      0.81      0.81       615\n",
            "\n",
            "======== fold 1 validation ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       529\n",
            "           1       0.76      0.61      0.68       240\n",
            "\n",
            "    accuracy                           0.82       769\n",
            "   macro avg       0.80      0.76      0.78       769\n",
            "weighted avg       0.81      0.82      0.81       769\n",
            "\n",
            "FOLD 2\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:07.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:13.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:20.\n",
            "\tAverage training loss: 2.14\n",
            "\tTraining epoch took: 0:00:20\n",
            "======== Validation report 1 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.82      0.84       389\n",
            "           1       0.71      0.75      0.73       226\n",
            "\n",
            "    accuracy                           0.80       615\n",
            "   macro avg       0.78      0.79      0.78       615\n",
            "weighted avg       0.80      0.80      0.80       615\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:28.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:34.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:41.\n",
            "\tAverage training loss: 1.52\n",
            "\tTraining epoch took: 0:00:41\n",
            "======== Validation report 2 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86       389\n",
            "           1       0.84      0.57      0.68       226\n",
            "\n",
            "    accuracy                           0.80       615\n",
            "   macro avg       0.81      0.75      0.77       615\n",
            "weighted avg       0.81      0.80      0.79       615\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:49.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:56.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:02.\n",
            "\tAverage training loss: 1.15\n",
            "\tTraining epoch took: 0:01:03\n",
            "======== Validation report 3 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       389\n",
            "           1       0.77      0.68      0.72       226\n",
            "\n",
            "    accuracy                           0.81       615\n",
            "   macro avg       0.80      0.78      0.79       615\n",
            "weighted avg       0.80      0.81      0.80       615\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:01:10.\n",
            "\tBatch   100  of    154.    Elapsed: 0:01:17.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:23.\n",
            "\tAverage training loss: 0.90\n",
            "\tTraining epoch took: 0:01:24\n",
            "======== Validation report 4 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.86       389\n",
            "           1       0.78      0.67      0.72       226\n",
            "\n",
            "    accuracy                           0.81       615\n",
            "   macro avg       0.80      0.78      0.79       615\n",
            "weighted avg       0.81      0.81      0.81       615\n",
            "\n",
            "======== fold 2 validation ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       529\n",
            "           1       0.74      0.63      0.68       240\n",
            "\n",
            "    accuracy                           0.82       769\n",
            "   macro avg       0.79      0.76      0.78       769\n",
            "weighted avg       0.81      0.82      0.81       769\n",
            "\n",
            "FOLD 3\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:06.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:13.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:19.\n",
            "\tAverage training loss: 2.17\n",
            "\tTraining epoch took: 0:00:20\n",
            "======== Validation report 1 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.98      0.84       390\n",
            "           1       0.91      0.41      0.57       225\n",
            "\n",
            "    accuracy                           0.77       615\n",
            "   macro avg       0.83      0.70      0.71       615\n",
            "weighted avg       0.80      0.77      0.74       615\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:28.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:34.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:41.\n",
            "\tAverage training loss: 1.62\n",
            "\tTraining epoch took: 0:00:41\n",
            "======== Validation report 2 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86       390\n",
            "           1       0.79      0.66      0.72       225\n",
            "\n",
            "    accuracy                           0.81       615\n",
            "   macro avg       0.81      0.78      0.79       615\n",
            "weighted avg       0.81      0.81      0.81       615\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:49.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:56.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:02.\n",
            "\tAverage training loss: 1.27\n",
            "\tTraining epoch took: 0:01:03\n",
            "======== Validation report 3 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85       390\n",
            "           1       0.74      0.76      0.75       225\n",
            "\n",
            "    accuracy                           0.81       615\n",
            "   macro avg       0.80      0.80      0.80       615\n",
            "weighted avg       0.81      0.81      0.81       615\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:01:10.\n",
            "\tBatch   100  of    154.    Elapsed: 0:01:17.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:23.\n",
            "\tAverage training loss: 1.01\n",
            "\tTraining epoch took: 0:01:24\n",
            "======== Validation report 4 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       390\n",
            "           1       0.77      0.70      0.73       225\n",
            "\n",
            "    accuracy                           0.81       615\n",
            "   macro avg       0.80      0.79      0.79       615\n",
            "weighted avg       0.81      0.81      0.81       615\n",
            "\n",
            "======== fold 3 validation ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       529\n",
            "           1       0.74      0.65      0.69       240\n",
            "\n",
            "    accuracy                           0.82       769\n",
            "   macro avg       0.80      0.78      0.78       769\n",
            "weighted avg       0.82      0.82      0.82       769\n",
            "\n",
            "FOLD 4\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:06.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:13.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:19.\n",
            "\tAverage training loss: 2.23\n",
            "\tTraining epoch took: 0:00:20\n",
            "======== Validation report 1 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86       407\n",
            "           1       0.79      0.57      0.66       207\n",
            "\n",
            "    accuracy                           0.80       614\n",
            "   macro avg       0.80      0.74      0.76       614\n",
            "weighted avg       0.80      0.80      0.79       614\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:28.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:34.\n",
            "\tBatch   150  of    154.    Elapsed: 0:00:41.\n",
            "\tAverage training loss: 1.65\n",
            "\tTraining epoch took: 0:00:41\n",
            "======== Validation report 2 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       407\n",
            "           1       0.78      0.63      0.70       207\n",
            "\n",
            "    accuracy                           0.82       614\n",
            "   macro avg       0.81      0.77      0.78       614\n",
            "weighted avg       0.81      0.82      0.81       614\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:00:49.\n",
            "\tBatch   100  of    154.    Elapsed: 0:00:55.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:02.\n",
            "\tAverage training loss: 1.20\n",
            "\tTraining epoch took: 0:01:02\n",
            "======== Validation report 3 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       407\n",
            "           1       0.76      0.71      0.73       207\n",
            "\n",
            "    accuracy                           0.83       614\n",
            "   macro avg       0.81      0.80      0.80       614\n",
            "weighted avg       0.82      0.83      0.82       614\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "\tBatch    50  of    154.    Elapsed: 0:01:10.\n",
            "\tBatch   100  of    154.    Elapsed: 0:01:16.\n",
            "\tBatch   150  of    154.    Elapsed: 0:01:23.\n",
            "\tAverage training loss: 0.87\n",
            "\tTraining epoch took: 0:01:23\n",
            "======== Validation report 4 / 4 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       407\n",
            "           1       0.73      0.69      0.71       207\n",
            "\n",
            "    accuracy                           0.81       614\n",
            "   macro avg       0.79      0.78      0.78       614\n",
            "weighted avg       0.81      0.81      0.81       614\n",
            "\n",
            "======== fold 4 validation ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       529\n",
            "           1       0.71      0.67      0.69       240\n",
            "\n",
            "    accuracy                           0.81       769\n",
            "   macro avg       0.78      0.77      0.78       769\n",
            "weighted avg       0.81      0.81      0.81       769\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgxVDjRZFOxO",
        "outputId": "91eaddfb-b743-43ff-fa7e-7be4f0b04845"
      },
      "source": [
        "model.eval()\n",
        "report = validate(model, test_dataloader)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.91      0.88       529\n",
            "           1       0.77      0.68      0.72       240\n",
            "\n",
            "    accuracy                           0.84       769\n",
            "   macro avg       0.82      0.80      0.80       769\n",
            "weighted avg       0.83      0.84      0.83       769\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-kQ0VDXrsP-"
      },
      "source": [
        "#Garbage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "XDYZ54M5iCqU",
        "outputId": "2f6081f5-fddd-46dc-cdc8-320d751fe1fd"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "OUTPUT_DIR = os.path.join(ROOT_DIR, 'labse_ft_results')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = OUTPUT_DIR,          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=0,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir=os.path.join(OUTPUT_DIR, 'logs'),            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=custom_model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset             # evaluation dataset\n",
        ")\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 3074\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 579\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-f4c3606a0c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m             \u001b[0;31m# evaluation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1278\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1803\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'input_ids'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqnZ9tL1h3si"
      },
      "source": [
        "max_len = 64\n",
        "row = train_df.iloc[0]\n",
        "texts = row.text\n",
        "encoded_input = tokenizer([texts, texts], padding=True, truncation=True, max_length=max_len, return_tensors='pt').to(device=DEVICE)\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "embeddings = model_output.pooler_output\n",
        "embeddings = torch.nn.functional.normalize(embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSGB8qxLZhKR",
        "outputId": "90210d94-4ed9-4c1a-915b-ce693d926df0"
      },
      "source": [
        "model_output.pooler_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__jZ2E4GfMch"
      },
      "source": [
        "train_embedings = text_encoder(train_texts, model, tokenizer, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90XN-tYKmgGk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkqo7q2ohNr7"
      },
      "source": [
        "sentences = [\"Hello World\"]\n",
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=max_len, return_tensors='pt').to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "embeddings = model_output.pooler_output\n",
        "embeddings = torch.nn.functional.normalize(embeddings)\n",
        "# print(embeddings[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf87TF-3um1S",
        "outputId": "ccbd18ec-f93e-44f1-856d-bf7a1cb99522"
      },
      "source": [
        "model_output.pooler_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFaqzhP4xDh_",
        "outputId": "31272612-dc58-4edd-df7f-78c47ad35ab1"
      },
      "source": [
        "model.parameters()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f24480df4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3qEzlo2fHVc",
        "outputId": "4d34e4fd-c9e6-4e61-b49b-2638c6b1be0b"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCmXOdSXUkIY"
      },
      "source": [
        "\n",
        "\n",
        "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
        "val_dataset = IMDbDataset(val_encodings, val_labels)\n",
        "test_dataset = IMDbDataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2alm0UHwp_L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehujnukbAoWe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}