{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTweet_k-fold.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k-kQ0VDXrsP-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97775e1ac6f143fe8630fbce731dd59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ceebbc23d761417ea23aad88ab98a0f3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e64ffe8c94e4285920ee429880484da",
              "IPY_MODEL_e615a6b4915e44e7ad5f3727a0809bbf",
              "IPY_MODEL_c36356386be1400f94c0ed63990d0323"
            ]
          }
        },
        "ceebbc23d761417ea23aad88ab98a0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e64ffe8c94e4285920ee429880484da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_80d2e84e610a4db4bb6eca90e30bd4fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb33ab9153e247ef903a2ea41615deaa"
          }
        },
        "e615a6b4915e44e7ad5f3727a0809bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_48eefd0949c5485ea49024c8bd3ce108",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 558,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 558,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bdbbdd418344ee4968dc79ef0032975"
          }
        },
        "c36356386be1400f94c0ed63990d0323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f63ba00665e473e857939078c55b849",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 558/558 [00:00&lt;00:00, 14.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_537a5f0590b446ca8c2a160ec0a8a9f1"
          }
        },
        "80d2e84e610a4db4bb6eca90e30bd4fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb33ab9153e247ef903a2ea41615deaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48eefd0949c5485ea49024c8bd3ce108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bdbbdd418344ee4968dc79ef0032975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f63ba00665e473e857939078c55b849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "537a5f0590b446ca8c2a160ec0a8a9f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc49c5e368e243a68c0e5989cddefdf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_abcda72d5e3e48f78d28fae4276a5bc0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c825ece445f04078b8eb57a98c6af3ec",
              "IPY_MODEL_e25d80bcd0394a3f87aa366956c97a11",
              "IPY_MODEL_01bc4e48949d4757892612844c6b9c57"
            ]
          }
        },
        "abcda72d5e3e48f78d28fae4276a5bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c825ece445f04078b8eb57a98c6af3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11caa27248e64d3eb356fecf6bab5b10",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30b553f51a504ebfa21991ff3702688b"
          }
        },
        "e25d80bcd0394a3f87aa366956c97a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd39a0d3e17d40ef8bf719e0e14e91b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 843438,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 843438,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73744f2516f24fee93b338c55f71b5d9"
          }
        },
        "01bc4e48949d4757892612844c6b9c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d9ebc50f05d1482888003df15a662d3c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 843k/843k [00:00&lt;00:00, 1.68MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffe288b26d1e44aa911e8384bf8c2c19"
          }
        },
        "11caa27248e64d3eb356fecf6bab5b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30b553f51a504ebfa21991ff3702688b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd39a0d3e17d40ef8bf719e0e14e91b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73744f2516f24fee93b338c55f71b5d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9ebc50f05d1482888003df15a662d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffe288b26d1e44aa911e8384bf8c2c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "902156f9a4e5407eaf5babae1988c08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5334f260b1f64ba18adf9e632012656e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_22dc924b900a40ec8a59b1e100a86495",
              "IPY_MODEL_ab09ee9755e046c09815d97c92d41193",
              "IPY_MODEL_6292b997ee9a4ac6837650187c34c5b3"
            ]
          }
        },
        "5334f260b1f64ba18adf9e632012656e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22dc924b900a40ec8a59b1e100a86495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4f4b45025a6f4cbe97002a8159e73437",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbf9f3604d80429fbb703ad277003302"
          }
        },
        "ab09ee9755e046c09815d97c92d41193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_974eea913a66420f96ba0d7658eb3793",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1078931,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1078931,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6df3d05d0654448b0b0c05ddb2edbf8"
          }
        },
        "6292b997ee9a4ac6837650187c34c5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5095f65d1b634265af687706adda0d7c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.08M/1.08M [00:00&lt;00:00, 3.92MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f09d625a98d248cda8106def1f38f359"
          }
        },
        "4f4b45025a6f4cbe97002a8159e73437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbf9f3604d80429fbb703ad277003302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "974eea913a66420f96ba0d7658eb3793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6df3d05d0654448b0b0c05ddb2edbf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5095f65d1b634265af687706adda0d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f09d625a98d248cda8106def1f38f359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ixomaxip/nasoc/blob/master/src/BERTweet_k_fold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8SipYd8wXSs",
        "outputId": "7cac4edd-5d44-4299-fbc2-9178c818948b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug 12 13:21:10 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ToLnryTqUg-"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install nltk emoji\n",
        "!pip install tweet-preprocessor\n",
        "\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "\n",
        "!wget https://hasocfire.github.io/hasoc/2021/files/en_Hasoc2021_train.zip\n",
        "!unzip -P hasoc2021_en en_Hasoc2021_train.zip\n",
        "!ls\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVRtn1TZSxGK",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARQ02wGdHGXR",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# !rm -rf /root/.ssh\n",
        "# !mkdir /root/.ssh\n",
        "# # !tar -xvzf ssh.tar.gz -C /root/.ssh && rm -rf ssh.tar.gz && chmod 700 /root/.ssh\n",
        "# !tar -xvzf ssh.tar.gz -C /root/.ssh && rm -rf ssh.tar.gz\n",
        "# !ssh-keyscan -t rsa github.com >> /root/.ssh/known_hosts\n",
        "\n",
        "# !git config --global user.email 'ixomaxip@gmail.com'\n",
        "# !git config --global user.user 'ixomaxip'\n",
        "# !ssh -T git@github.com\n",
        "\n",
        "# !git clone git@github.com:ixomaxip/nasoc.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3QnjK3TdjmO"
      },
      "source": [
        "# Custom BERTweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K18B6AOMH599"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import datetime\n",
        "import re\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "#constants and parameters\n",
        "seed = 42\n",
        "\n",
        "path_gdrive_saved = '/content/drive/My Drive/nasoc/bert_tuned.weights'\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "DOWNLOAD_DATASET = False\n",
        "\n",
        "# dataset\n",
        "\n",
        "raw_df = pd.read_csv('en_Hasoc2021_train.csv')\n",
        "\n",
        "raw_df['inputs'] = pd.Categorical(raw_df['task_1'])\n",
        "raw_df['inputs'] = raw_df.inputs.cat.codes\n",
        "\n",
        "raw_df['task_2_cat'] = pd.Categorical(raw_df['task_2'])\n",
        "raw_df['task_2_cat'] = raw_df.task_2_cat.cat.codes\n",
        "\n",
        "train_df, test_df = train_test_split(raw_df, test_size=0.2, random_state=seed)\n",
        "\n",
        "sr_train = train_df.groupby('task_1').count()['text']\n",
        "sr_test  = test_df.groupby('task_1').count()['text']\n",
        "\n",
        "tr_pr = sr_train['NOT']/sr_train['HOF']\n",
        "ts_pr = sr_test['NOT']/sr_test['HOF']\n",
        "\n",
        "#copied from https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)\n",
        "\n",
        "# copied from https://stackoverflow.com/questions/64719706/cleaning-twitter-data-pandas-python\n",
        "def cleaner(tweet):\n",
        "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
        "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
        "    #tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
        "    tweet = \" \".join(tweet.split())\n",
        "    tweet = remove_emojis(tweet)\n",
        "    #tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
        "    #     if w.lower() in words or not w.isalpha())\n",
        "    return tweet\n",
        "\n",
        "raw_df_tmp = raw_df.copy(True)\n",
        "train_df, test_df = train_test_split(raw_df_tmp, test_size=0.2, random_state=seed)\n",
        "#text = train_df.pop('text')#.map(lambda line: cleaner(line))\n",
        "#label = train_df.pop('inputs')\n",
        "\n",
        "#text_val = test_df.pop('text')#.map(lambda line: cleaner(line))\n",
        "#label_val = test_df.pop('inputs')\n",
        "\n",
        "#train_ds = tf.data.Dataset.from_tensor_slices((text.values, label.values))\n",
        "#val_ds = tf.data.Dataset.from_tensor_slices((text_val.values, label_val.values))\n",
        "\n",
        "#train_ds = train_ds.batch(batch_size=batch_size, drop_remainder=True)\n",
        "#val_ds = val_ds.batch(batch_size=batch_size, drop_remainder=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONcydGgGsaqt"
      },
      "source": [
        "import time, datetime\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F, Linear\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GubgnSZx4jcf"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "97775e1ac6f143fe8630fbce731dd59c",
            "ceebbc23d761417ea23aad88ab98a0f3",
            "9e64ffe8c94e4285920ee429880484da",
            "e615a6b4915e44e7ad5f3727a0809bbf",
            "c36356386be1400f94c0ed63990d0323",
            "80d2e84e610a4db4bb6eca90e30bd4fa",
            "fb33ab9153e247ef903a2ea41615deaa",
            "48eefd0949c5485ea49024c8bd3ce108",
            "4bdbbdd418344ee4968dc79ef0032975",
            "1f63ba00665e473e857939078c55b849",
            "537a5f0590b446ca8c2a160ec0a8a9f1",
            "bc49c5e368e243a68c0e5989cddefdf9",
            "abcda72d5e3e48f78d28fae4276a5bc0",
            "c825ece445f04078b8eb57a98c6af3ec",
            "e25d80bcd0394a3f87aa366956c97a11",
            "01bc4e48949d4757892612844c6b9c57",
            "11caa27248e64d3eb356fecf6bab5b10",
            "30b553f51a504ebfa21991ff3702688b",
            "bd39a0d3e17d40ef8bf719e0e14e91b9",
            "73744f2516f24fee93b338c55f71b5d9",
            "d9ebc50f05d1482888003df15a662d3c",
            "ffe288b26d1e44aa911e8384bf8c2c19",
            "902156f9a4e5407eaf5babae1988c08e",
            "5334f260b1f64ba18adf9e632012656e",
            "22dc924b900a40ec8a59b1e100a86495",
            "ab09ee9755e046c09815d97c92d41193",
            "6292b997ee9a4ac6837650187c34c5b3",
            "4f4b45025a6f4cbe97002a8159e73437",
            "dbf9f3604d80429fbb703ad277003302",
            "974eea913a66420f96ba0d7658eb3793",
            "a6df3d05d0654448b0b0c05ddb2edbf8",
            "5095f65d1b634265af687706adda0d7c",
            "f09d625a98d248cda8106def1f38f359"
          ]
        },
        "id": "ocg_xpB_hALs",
        "outputId": "d29fa6ce-a702-481b-e578-f4e91b8ad601"
      },
      "source": [
        "class HasocDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=64, return_tensors='pt')\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "#MODEL_NAME = \"cardiffnlp/twitter-roberta-base-hate\"\n",
        "MODEL_NAME = \"vinai/bertweet-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "train_dataset = HasocDataset(train_df['text'].to_list(), train_df['inputs'].to_list(), tokenizer)\n",
        "test_dataset = HasocDataset(test_df['text'].to_list(), test_df['inputs'].to_list(), tokenizer)\n",
        "\n",
        "raw_dataset = HasocDataset(raw_df['text'].to_list(), raw_df['inputs'].to_list(), tokenizer)\n",
        "\n",
        "BATCH_SIZE = 16\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97775e1ac6f143fe8630fbce731dd59c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/558 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc49c5e368e243a68c0e5989cddefdf9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/843k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "902156f9a4e5407eaf5babae1988c08e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMC2E1uJ4BDQ"
      },
      "source": [
        "# it = iter(test_dataloader)\n",
        "# first = next(it)\n",
        "\n",
        "# print(first)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iNBpJxQGhlc"
      },
      "source": [
        "## Customization class & auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wghRCjFwp5rT"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# DEVICE = torch.device('cpu')\n",
        "\n",
        "# Customization\n",
        "class CustomBERTweet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBERTweet, self).__init__()\n",
        "        self.bertweet = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        #self.cnn = nn.Conv1d(1, 768, 3)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.dense1 = nn.Linear(768, 2)\n",
        "        # self.dense2 = nn.Linear(256, 2)\n",
        "    \n",
        "    def forward(self, feed_dict):\n",
        "\n",
        "        bertweet_output = self.bertweet(**feed_dict)\n",
        "        drop_output = self.dropout(bertweet_output.pooler_output)\n",
        "        linear1_output = self.dense1(drop_output)\n",
        "        # linear2_output = self.dense2(linear1_output)\n",
        "\n",
        "        return linear1_output\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def forward(batch, model):\n",
        "    feed_dict = {\n",
        "        'input_ids': batch['input_ids'].to(DEVICE),\n",
        "        'token_type_ids': batch['token_type_ids'].to(DEVICE),\n",
        "        'attention_mask': batch['attention_mask'].to(DEVICE),\n",
        "    }\n",
        "    # feed_dict = {\n",
        "    #     'input_ids': batch['input_ids'].to(DEVICE),\n",
        "    #     'token_type_ids': batch['token_type_ids'].to(DEVICE),\n",
        "    #     'attention_mask': batch['attention_mask'].to(DEVICE),\n",
        "    # }    \n",
        "    outputs = model(feed_dict)\n",
        "    outputs = F.log_softmax(outputs, dim=1)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "def validate(model, dataloader, as_dict=False):\n",
        "    predictions, targets = [], []\n",
        "    for batch in dataloader:\n",
        "        target = batch['labels']\n",
        "        with torch.no_grad():\n",
        "            logits = forward(batch, model)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label = target.to('cpu').numpy()        \n",
        "        predictions.append(logits)\n",
        "        targets.append(label)\n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "    flat_targets = [item for sublist in targets for item in sublist]\n",
        "    return classification_report(flat_targets, flat_predictions, output_dict=as_dict)\n",
        "\n",
        "def reset_weights(m):\n",
        "    for layer in m.children():\n",
        "        if hasattr(layer, 'reset_parameters'):\n",
        "            #print(f'Reset trainable parameters of layer = {layer}')\n",
        "            layer.reset_parameters()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agXV9FD9BWAM"
      },
      "source": [
        "# del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA61MKDvGuCj"
      },
      "source": [
        "## Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voXHyVJmYIiG",
        "outputId": "df758102-5536-4fa2-913e-0d26f0bf520a"
      },
      "source": [
        "true_train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = BATCH_SIZE\n",
        ")\n",
        "true_test_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            sampler = RandomSampler(test_dataset),\n",
        "            batch_size = BATCH_SIZE\n",
        ")\n",
        "len(true_train_dataloader)\n",
        "\n",
        "#model = CustomBERTweet()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOj_5En0HAa9"
      },
      "source": [
        "## Check model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpKnFaGuG1Gb"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "print(f'The BERT model has {len(params):} different named parameters.\\n')\n",
        "print('==== Embedding Layer ====\\n')\n",
        "for p in params[0:5]:\n",
        "    print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "for p in params[5:21]:\n",
        "    print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "for p in params[-12:]:\n",
        "    print(f'{p[0]:<55} {str(tuple(p[1].size())):>12}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c48dAZ7BSaf8"
      },
      "source": [
        "model.to(torch.device('cuda'))\n",
        "print(validate(model, test_dataloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzNQK9-3Lh2w"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oasaOhW3yW2Y"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "k_folds = 2\n",
        "EPOCHS = 3\n",
        "\n",
        "# For fold results\n",
        "results = {}\n",
        "\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPgMJUf6_A7x",
        "outputId": "4db60035-70be-42b2-b7ec-d55927dd7098"
      },
      "source": [
        "# # model = CustomBERTweet()\n",
        "# # params = list(model.named_parameters())\n",
        "# # model.to(torch.device('cuda'))\n",
        "# # print(validate(model, test_dataloader))\n",
        "fold_results = []\n",
        "\n",
        "for fold, (train_ids_idx, test_ids_idx) in enumerate(kfold.split(train_dataset)):    \n",
        "    # Print\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "    \n",
        "#     # Sample elements randomly from a given list of ids, no replacement.\n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids_idx)\n",
        "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids_idx)\n",
        "    \n",
        "    # Define data loaders for training and testing data in this fold\n",
        "    k_fold_train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = train_subsampler,\n",
        "            batch_size = BATCH_SIZE\n",
        "    )\n",
        "    k_fold_test_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = test_subsampler,\n",
        "            batch_size = BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    model_kf = CustomBERTweet()\n",
        "\n",
        "    total_steps = len(k_fold_train_dataloader) * EPOCHS\n",
        "    optimizer = AdamW(model_kf.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                                num_warmup_steps = 20,\n",
        "                                                num_training_steps = total_steps)\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    model_kf.to(DEVICE)\n",
        "\n",
        "    #print(validate(model_kf, test_dataloader))\n",
        "\n",
        "    start = time.time()\n",
        "    for epoch in range(0, EPOCHS):\n",
        "        total_train_loss = 0\n",
        "        model_kf.train()\n",
        "        print(f'======== Epoch {epoch+1} / {EPOCHS} ========')\n",
        "        for step, batch in enumerate(k_fold_train_dataloader):\n",
        "            #print(f\"step: {step}\")\n",
        "            if step % 50 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - start)\n",
        "                print(f'\\tBatch {step:>5,}  of  {len(k_fold_train_dataloader):>5,}.    Elapsed: {elapsed}.')\n",
        "                # print(f'\\tloss: {loss.item()}')\n",
        "            optimizer.zero_grad()\n",
        "            outputs = forward(batch, model_kf)\n",
        "            target = batch['labels'].to(DEVICE)\n",
        "            model_kf.zero_grad()\n",
        "            loss = loss_func(outputs, target)\n",
        "            total_train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model_kf.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        \n",
        "        avg_train_loss = total_train_loss / len(k_fold_test_dataloader)\n",
        "        training_time = format_time(time.time() - start)\n",
        "        print(f'\\tAverage training loss: {avg_train_loss:.2f}')\n",
        "        print(f'\\tTraining epoch took: {training_time}')\n",
        "        model_kf.eval()\n",
        "        report = validate(model_kf, k_fold_test_dataloader)\n",
        "        print(f'======== Validation report {epoch+1} / {EPOCHS} ========')\n",
        "        print(report)\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(true_test_dataloader)\n",
        "    training_time = format_time(time.time() - start)\n",
        "    model_kf.eval()\n",
        "    report = validate(model_kf, true_test_dataloader, True)\n",
        "    fold_results.append(report)\n",
        "    #print(f'======== fold {fold} validation ========')\n",
        "    #print(report)\n",
        "\n",
        "print(report)\n",
        "    "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 3 ========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tBatch    50  of     97.    Elapsed: 0:00:06.\n",
            "\tAverage training loss: 0.59\n",
            "\tTraining epoch took: 0:00:12\n",
            "======== Validation report 1 / 3 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.83       985\n",
            "           1       0.72      0.58      0.64       552\n",
            "\n",
            "    accuracy                           0.77      1537\n",
            "   macro avg       0.76      0.73      0.74      1537\n",
            "weighted avg       0.77      0.77      0.76      1537\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "\tBatch    50  of     97.    Elapsed: 0:00:22.\n",
            "\tAverage training loss: 0.43\n",
            "\tTraining epoch took: 0:00:28\n",
            "======== Validation report 2 / 3 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       985\n",
            "           1       0.74      0.69      0.72       552\n",
            "\n",
            "    accuracy                           0.80      1537\n",
            "   macro avg       0.79      0.78      0.78      1537\n",
            "weighted avg       0.80      0.80      0.80      1537\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "\tBatch    50  of     97.    Elapsed: 0:00:38.\n",
            "\tAverage training loss: 0.33\n",
            "\tTraining epoch took: 0:00:44\n",
            "======== Validation report 3 / 3 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       985\n",
            "           1       0.76      0.66      0.71       552\n",
            "\n",
            "    accuracy                           0.80      1537\n",
            "   macro avg       0.79      0.77      0.78      1537\n",
            "weighted avg       0.80      0.80      0.80      1537\n",
            "\n",
            "FOLD 1\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 3 ========\n",
            "\tBatch    50  of     97.    Elapsed: 0:00:06.\n",
            "\tAverage training loss: 0.59\n",
            "\tTraining epoch took: 0:00:12\n",
            "======== Validation report 1 / 3 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.90      0.83       987\n",
            "           1       0.75      0.54      0.63       550\n",
            "\n",
            "    accuracy                           0.77      1537\n",
            "   macro avg       0.76      0.72      0.73      1537\n",
            "weighted avg       0.77      0.77      0.76      1537\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "\tBatch    50  of     97.    Elapsed: 0:00:22.\n",
            "\tAverage training loss: 0.40\n",
            "\tTraining epoch took: 0:00:28\n",
            "======== Validation report 2 / 3 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83       987\n",
            "           1       0.69      0.73      0.71       550\n",
            "\n",
            "    accuracy                           0.79      1537\n",
            "   macro avg       0.77      0.77      0.77      1537\n",
            "weighted avg       0.79      0.79      0.79      1537\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "\tBatch    50  of     97.    Elapsed: 0:00:38.\n",
            "\tAverage training loss: 0.29\n",
            "\tTraining epoch took: 0:00:44\n",
            "======== Validation report 3 / 3 ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.85       987\n",
            "           1       0.75      0.64      0.69       550\n",
            "\n",
            "    accuracy                           0.80      1537\n",
            "   macro avg       0.78      0.76      0.77      1537\n",
            "weighted avg       0.79      0.80      0.79      1537\n",
            "\n",
            "{'0': {'precision': 0.8436944937833037, 'recall': 0.8979206049149339, 'f1-score': 0.86996336996337, 'support': 529}, '1': {'precision': 0.7378640776699029, 'recall': 0.6333333333333333, 'f1-score': 0.6816143497757847, 'support': 240}, 'accuracy': 0.8153446033810143, 'macro avg': {'precision': 0.7907792857266034, 'recall': 0.7656269691241335, 'f1-score': 0.7757888598695774, 'support': 769}, 'weighted avg': {'precision': 0.8106654952563646, 'recall': 0.8153446033810143, 'f1-score': 0.8111808409061261, 'support': 769}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0ozgBD6iJtF",
        "outputId": "48659986-5820-4581-8849-fd01922de634"
      },
      "source": [
        "class_avg = {}\n",
        "\n",
        "if len(fold_results) > 0:\n",
        "    class_avg = fold_results[0]\n",
        "\n",
        "counter = 0\n",
        "\n",
        "# sum\n",
        "for fold_report in fold_results:\n",
        "    if counter == 0:\n",
        "        counter += 1\n",
        "        continue\n",
        "    \n",
        "    for key, value in fold_report.items(): #0, 1, accuracy...\n",
        "        if type(class_avg[key]) is float:\n",
        "            class_avg[key] += value\n",
        "        else:\n",
        "            for key_metr, value_metr in value.items():\n",
        "                class_avg[key][key_metr] += value_metr\n",
        "                \n",
        "    counter += 1\n",
        "\n",
        "# div\n",
        "for key, value in fold_report.items(): #0, 1, accuracy...\n",
        "    if type(class_avg[key]) is float:\n",
        "        class_avg[key] /= counter\n",
        "    else:\n",
        "        for key_metr, value_metr in value.items():\n",
        "            class_avg[key][key_metr] /= counter\n",
        "\n",
        "#print\n",
        "df = pd.DataFrame(class_avg)\n",
        "print(df.T)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score     support\n",
            "0              0.843260  0.896267  0.868953  529.000000\n",
            "1              0.734664  0.632812  0.679930  240.000000\n",
            "accuracy       0.814044  0.814044  0.814044    0.814044\n",
            "macro avg      0.788962  0.764540  0.774442  769.000000\n",
            "weighted avg   0.809368  0.814044  0.809960  769.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-kQ0VDXrsP-"
      },
      "source": [
        "#Garbage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "XDYZ54M5iCqU",
        "outputId": "2f6081f5-fddd-46dc-cdc8-320d751fe1fd"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "OUTPUT_DIR = os.path.join(ROOT_DIR, 'labse_ft_results')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = OUTPUT_DIR,          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=0,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir=os.path.join(OUTPUT_DIR, 'logs'),            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=custom_model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset             # evaluation dataset\n",
        ")\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 3074\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 579\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-f4c3606a0c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m             \u001b[0;31m# evaluation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1278\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1803\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'input_ids'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqnZ9tL1h3si"
      },
      "source": [
        "max_len = 64\n",
        "row = train_df.iloc[0]\n",
        "texts = row.text\n",
        "encoded_input = tokenizer([texts, texts], padding=True, truncation=True, max_length=max_len, return_tensors='pt').to(device=DEVICE)\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "embeddings = model_output.pooler_output\n",
        "embeddings = torch.nn.functional.normalize(embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSGB8qxLZhKR",
        "outputId": "90210d94-4ed9-4c1a-915b-ce693d926df0"
      },
      "source": [
        "model_output.pooler_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__jZ2E4GfMch"
      },
      "source": [
        "train_embedings = text_encoder(train_texts, model, tokenizer, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90XN-tYKmgGk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkqo7q2ohNr7"
      },
      "source": [
        "sentences = [\"Hello World\"]\n",
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=max_len, return_tensors='pt').to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "embeddings = model_output.pooler_output\n",
        "embeddings = torch.nn.functional.normalize(embeddings)\n",
        "# print(embeddings[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf87TF-3um1S",
        "outputId": "ccbd18ec-f93e-44f1-856d-bf7a1cb99522"
      },
      "source": [
        "model_output.pooler_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFaqzhP4xDh_",
        "outputId": "31272612-dc58-4edd-df7f-78c47ad35ab1"
      },
      "source": [
        "model.parameters()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f24480df4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3qEzlo2fHVc",
        "outputId": "4d34e4fd-c9e6-4e61-b49b-2638c6b1be0b"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCmXOdSXUkIY"
      },
      "source": [
        "\n",
        "\n",
        "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
        "val_dataset = IMDbDataset(val_encodings, val_labels)\n",
        "test_dataset = IMDbDataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2alm0UHwp_L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehujnukbAoWe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}